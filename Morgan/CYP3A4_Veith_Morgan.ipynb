{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NathanJiang/opt/anaconda3/envs/tf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2023.03.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm #progress bar\n",
    "import rdkit\n",
    "from rdkit import Chem #Chemistry\n",
    "from rdkit.Chem import rdMolDescriptors #molecular descriptors\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "rdkit.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 04:19:05.541342: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from sklearn.model_selection import train_test_split #ML training\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from yellowbrick.regressor import prediction_error, ResidualsPlot\n",
    "from tdc.single_pred import ADME\n",
    "from tdc.benchmark_group import admet_group\n",
    "from tdc import BenchmarkGroup\n",
    "from tdc import Evaluator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_prob_to_score(pred_prob):\n",
    "    res = []\n",
    "    for i in range(len(pred_prob)):\n",
    "        res.append(pred_prob[i][1])\n",
    "    res = np.array(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "generating training, validation splits...\n",
      "100%|██████████| 9861/9861 [00:05<00:00, 1914.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[04:19:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  26.5s\n",
      "[04:20:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  27.2s\n",
      "[04:20:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  24.5s\n",
      "[04:21:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  34.4s\n",
      "[04:21:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  34.9s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.867 total time= 2.3min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.849 total time= 2.4min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.876 total time= 2.4min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.861 total time= 2.3min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.868 total time= 2.2min\n",
      "[04:33:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  25.6s\n",
      "[04:34:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  25.8s\n",
      "[04:34:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  27.4s\n",
      "[04:34:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  26.6s\n",
      "[04:35:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  27.7s\n",
      "[04:35:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  27.4s\n",
      "[04:36:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  28.2s\n",
      "[04:36:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  27.0s\n",
      "[04:37:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  42.1s\n",
      "[04:37:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  28.8s\n",
      "[04:38:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  18.2s\n",
      "[04:38:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  18.2s\n",
      "[04:39:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  24.1s\n",
      "[04:39:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  17.8s\n",
      "[04:39:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  27.3s\n",
      "[04:40:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  21.7s\n",
      "[04:40:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  20.5s\n",
      "[04:40:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  19.9s\n",
      "[04:41:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  18.1s\n",
      "[04:41:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  14.2s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.872 total time= 6.0min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.853 total time= 6.4min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.885 total time= 6.4min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.870 total time= 6.4min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.878 total time= 6.4min\n",
      "[05:13:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  16.8s\n",
      "[05:13:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  14.7s\n",
      "[05:13:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  14.6s\n",
      "[05:14:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  21.9s\n",
      "[05:14:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  14.9s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.873 total time= 7.9min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.851 total time= 8.3min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.884 total time= 8.6min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.874 total time= 8.5min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.874 total time= 7.5min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.870 total time= 2.7min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.849 total time= 2.8min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.877 total time= 2.8min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.870 total time= 2.7min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.875 total time= 2.7min\n",
      "[06:09:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  21.1s\n",
      "[06:09:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  21.1s\n",
      "[06:09:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  21.0s\n",
      "[06:10:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  19.8s\n",
      "[06:10:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  20.0s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.872 total time= 3.1min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.848 total time= 3.3min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.876 total time= 3.3min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.869 total time= 3.2min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.869 total time= 3.1min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.869 total time= 1.9min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.849 total time= 1.9min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.875 total time= 1.8min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.861 total time= 2.0min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.868 total time= 2.0min\n",
      "[06:36:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  32.1s\n",
      "[06:37:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  32.9s\n",
      "[06:37:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  25.6s\n",
      "[06:38:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  25.9s\n",
      "[06:38:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  31.9s\n",
      "[06:39:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  17.6s\n",
      "[06:39:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  26.0s\n",
      "[06:39:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  24.8s\n",
      "[06:40:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  18.9s\n",
      "[06:40:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  18.9s\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.780 total time= 1.7min\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=0.758 total time= 1.8min\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.810 total time= 1.9min\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=0.784 total time= 1.7min\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=0.785 total time= 1.7min\n",
      "[CV 1/5] END .................C=1, gamma=0.0001;, score=0.601 total time= 2.0min\n",
      "[CV 2/5] END .................C=1, gamma=0.0001;, score=0.616 total time= 2.1min\n",
      "[CV 3/5] END .................C=1, gamma=0.0001;, score=0.592 total time= 2.0min\n",
      "[CV 4/5] END .................C=1, gamma=0.0001;, score=0.601 total time= 2.0min\n",
      "[CV 5/5] END .................C=1, gamma=0.0001;, score=0.604 total time= 2.0min\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.761 total time= 2.6min\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.759 total time= 2.7min\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.775 total time= 2.6min\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.778 total time= 2.7min\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.784 total time= 3.0min\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.578 total time= 2.8min\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.579 total time= 2.8min\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.579 total time= 2.8min\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.579 total time= 2.8min\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.579 total time= 2.8min\n",
      "[CV 1/5] END ..............C=1000, gamma=0.0001;, score=0.774 total time= 1.5min\n",
      "[CV 2/5] END ..............C=1000, gamma=0.0001;, score=0.747 total time= 1.4min\n",
      "[CV 3/5] END ..............C=1000, gamma=0.0001;, score=0.782 total time= 1.5min\n",
      "[CV 4/5] END ..............C=1000, gamma=0.0001;, score=0.787 total time= 1.5min\n",
      "[CV 5/5] END ..............C=1000, gamma=0.0001;, score=0.779 total time= 1.4min\n",
      "[CV 1/5] END ..................C=0.1, gamma=0.1;, score=0.579 total time= 2.5min\n",
      "[CV 2/5] END ..................C=0.1, gamma=0.1;, score=0.579 total time= 2.5min\n",
      "[CV 3/5] END ..................C=0.1, gamma=0.1;, score=0.579 total time= 2.5min\n",
      "[CV 4/5] END ..................C=0.1, gamma=0.1;, score=0.579 total time= 2.6min\n",
      "[CV 5/5] END ..................C=0.1, gamma=0.1;, score=0.579 total time= 2.6min\n",
      "[CV 1/5] END ................C=0.1, gamma=0.001;, score=0.598 total time= 2.5min\n",
      "[CV 2/5] END ................C=0.1, gamma=0.001;, score=0.614 total time= 3.1min\n",
      "[CV 3/5] END ................C=0.1, gamma=0.001;, score=0.591 total time= 3.2min\n",
      "[CV 4/5] END ................C=0.1, gamma=0.001;, score=0.597 total time= 3.1min\n",
      "[CV 5/5] END ................C=0.1, gamma=0.001;, score=0.598 total time= 2.9min\n",
      "[CV 1/5] END ......................C=1, gamma=1;, score=0.578 total time= 2.9min\n",
      "[CV 2/5] END ......................C=1, gamma=1;, score=0.579 total time= 2.9min\n",
      "[CV 3/5] END ......................C=1, gamma=1;, score=0.579 total time= 3.0min\n",
      "[CV 4/5] END ......................C=1, gamma=1;, score=0.579 total time= 3.0min\n",
      "[CV 5/5] END ......................C=1, gamma=1;, score=0.579 total time= 3.5min\n",
      "[CV 1/5] END ..................C=100, gamma=0.1;, score=0.761 total time= 3.1min\n",
      "[CV 2/5] END ..................C=100, gamma=0.1;, score=0.759 total time= 3.1min\n",
      "[CV 3/5] END ..................C=100, gamma=0.1;, score=0.775 total time= 3.2min\n",
      "[CV 4/5] END ..................C=100, gamma=0.1;, score=0.778 total time= 3.0min\n",
      "[CV 5/5] END ..................C=100, gamma=0.1;, score=0.784 total time= 2.9min\n",
      "[CV 1/5] END ................C=10, gamma=0.0001;, score=0.771 total time= 2.2min\n",
      "[CV 2/5] END ................C=10, gamma=0.0001;, score=0.754 total time= 2.2min\n",
      "[CV 3/5] END ................C=10, gamma=0.0001;, score=0.768 total time= 2.3min\n",
      "[CV 4/5] END ................C=10, gamma=0.0001;, score=0.754 total time= 2.2min\n",
      "[CV 5/5] END ................C=10, gamma=0.0001;, score=0.753 total time= 2.3min\n",
      "[CV 1/5] END .................C=0.1, gamma=0.01;, score=0.765 total time= 2.3min\n",
      "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.760 total time= 2.4min\n",
      "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.761 total time= 2.4min\n",
      "[CV 4/5] END .................C=0.1, gamma=0.01;, score=0.750 total time= 2.3min\n",
      "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.753 total time= 2.4min\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.773 total time= 2.0min\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.747 total time= 1.9min\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.787 total time= 2.0min\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.780 total time= 2.0min\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.779 total time= 1.9min\n",
      "[CV 1/5] END ...................C=1, gamma=0.01;, score=0.797 total time= 1.8min\n",
      "[CV 2/5] END ...................C=1, gamma=0.01;, score=0.773 total time= 1.8min\n",
      "[CV 3/5] END ...................C=1, gamma=0.01;, score=0.787 total time= 1.9min\n",
      "[CV 4/5] END ...................C=1, gamma=0.01;, score=0.795 total time= 1.8min\n",
      "[CV 5/5] END ...................C=1, gamma=0.01;, score=0.804 total time= 1.8min\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.791 total time= 1.8min\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.770 total time= 1.8min\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.806 total time= 1.8min\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.794 total time= 1.8min\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.799 total time= 1.8min\n",
      "[CV 1/5] END ...............C=0.1, gamma=0.0001;, score=0.579 total time= 2.6min\n",
      "[CV 2/5] END ...............C=0.1, gamma=0.0001;, score=0.579 total time= 2.7min\n",
      "[CV 3/5] END ...............C=0.1, gamma=0.0001;, score=0.579 total time= 2.7min\n",
      "[CV 4/5] END ...............C=0.1, gamma=0.0001;, score=0.579 total time= 2.8min\n",
      "[CV 5/5] END ...............C=0.1, gamma=0.0001;, score=0.579 total time= 3.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 09:47:46.095785: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 5ms/step\n",
      "78/78 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n",
      "100%|██████████| 9861/9861 [00:04<00:00, 2226.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[09:49:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  13.3s\n",
      "[09:49:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  15.2s\n",
      "[09:49:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  18.1s\n",
      "[09:49:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  17.9s\n",
      "[09:50:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  18.3s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.880 total time= 2.6min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.846 total time= 2.6min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.865 total time= 2.6min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.873 total time= 2.7min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.851 total time= 2.7min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.883 total time= 3.9min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.854 total time= 3.4min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.874 total time= 3.5min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.879 total time= 3.6min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.855 total time= 3.3min\n",
      "[10:21:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  11.9s\n",
      "[10:21:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  13.8s\n",
      "[10:21:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  15.1s\n",
      "[10:22:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  15.2s\n",
      "[10:22:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  16.5s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.885 total time= 5.3min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.852 total time= 5.6min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.878 total time= 8.3min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.878 total time= 9.0min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.862 total time= 9.1min\n",
      "[10:59:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  41.1s\n",
      "[11:00:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  35.6s\n",
      "[11:01:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  39.8s\n",
      "[11:01:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  34.5s\n",
      "[11:02:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  28.6s\n",
      "[11:02:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  17.7s\n",
      "[11:03:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  19.8s\n",
      "[11:03:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  18.7s\n",
      "[11:03:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  20.0s\n",
      "[11:04:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  22.0s\n",
      "[11:04:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  13.0s\n",
      "[11:04:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  14.7s\n",
      "[11:05:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  13.4s\n",
      "[11:05:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  14.3s\n",
      "[11:05:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  14.8s\n",
      "[11:05:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=  14.8s\n",
      "[11:05:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=  12.9s\n",
      "[11:06:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=  14.9s\n",
      "[11:06:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=  14.5s\n",
      "[11:06:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=  14.5s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.879 total time= 6.5min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.844 total time= 6.0min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.872 total time= 5.7min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.871 total time= 6.0min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.854 total time= 5.7min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.884 total time= 3.7min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.845 total time= 3.4min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.871 total time= 3.6min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.876 total time= 4.0min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.852 total time= 4.0min\n",
      "[11:55:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  20.3s\n",
      "[11:55:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  20.9s\n",
      "[11:56:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  18.1s\n",
      "[11:56:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  17.7s\n",
      "[11:56:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  15.2s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.877 total time= 3.1min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.846 total time= 3.9min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.867 total time= 4.3min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.874 total time= 4.1min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.853 total time= 3.6min\n",
      "[12:16:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  13.7s\n",
      "[12:16:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  13.9s\n",
      "[12:16:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  13.9s\n",
      "[12:16:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  13.9s\n",
      "[12:16:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  14.2s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.879 total time= 4.7min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.850 total time= 4.3min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.872 total time= 4.5min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.879 total time= 4.4min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.856 total time= 4.5min\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END ................C=100, gamma=0.001;, score=0.780 total time= 1.5min\n",
      "[CV 2/5] END ................C=100, gamma=0.001;, score=0.739 total time= 1.5min\n",
      "[CV 3/5] END ................C=100, gamma=0.001;, score=0.797 total time= 1.5min\n",
      "[CV 4/5] END ................C=100, gamma=0.001;, score=0.775 total time= 1.6min\n",
      "[CV 5/5] END ................C=100, gamma=0.001;, score=0.757 total time= 1.5min\n",
      "[CV 1/5] END ................C=10, gamma=0.0001;, score=0.765 total time= 2.2min\n",
      "[CV 2/5] END ................C=10, gamma=0.0001;, score=0.753 total time= 2.1min\n",
      "[CV 3/5] END ................C=10, gamma=0.0001;, score=0.767 total time= 2.2min\n",
      "[CV 4/5] END ................C=10, gamma=0.0001;, score=0.773 total time= 2.1min\n",
      "[CV 5/5] END ................C=10, gamma=0.0001;, score=0.742 total time= 2.1min\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.776 total time= 2.9min\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.756 total time= 2.8min\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.776 total time= 2.8min\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.765 total time= 3.2min\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.759 total time= 3.1min\n",
      "[CV 1/5] END .................C=0.1, gamma=0.01;, score=0.753 total time= 2.6min\n",
      "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.745 total time= 2.4min\n",
      "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.757 total time= 2.5min\n",
      "[CV 4/5] END .................C=0.1, gamma=0.01;, score=0.768 total time= 2.4min\n",
      "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.736 total time= 2.4min\n",
      "[CV 1/5] END ................C=0.1, gamma=0.001;, score=0.602 total time= 2.8min\n",
      "[CV 2/5] END ................C=0.1, gamma=0.001;, score=0.611 total time= 2.7min\n",
      "[CV 3/5] END ................C=0.1, gamma=0.001;, score=0.604 total time= 2.7min\n",
      "[CV 4/5] END ................C=0.1, gamma=0.001;, score=0.608 total time= 2.7min\n",
      "[CV 5/5] END ................C=0.1, gamma=0.001;, score=0.620 total time= 2.7min\n",
      "[CV 1/5] END ......................C=1, gamma=1;, score=0.598 total time= 3.4min\n",
      "[CV 2/5] END ......................C=1, gamma=1;, score=0.597 total time= 3.4min\n",
      "[CV 3/5] END ......................C=1, gamma=1;, score=0.598 total time= 3.3min\n",
      "[CV 4/5] END ......................C=1, gamma=1;, score=0.598 total time= 3.3min\n",
      "[CV 5/5] END ......................C=1, gamma=1;, score=0.597 total time= 3.3min\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.598 total time= 3.5min\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.597 total time= 3.5min\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.598 total time= 3.6min\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.598 total time= 3.3min\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.597 total time= 3.3min\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.789 total time= 1.9min\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.775 total time= 1.9min\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.798 total time= 1.9min\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.785 total time= 1.9min\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.767 total time= 1.9min\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.798 total time= 2.1min\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.740 total time= 2.1min\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.784 total time= 2.2min\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.774 total time= 2.1min\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.773 total time= 1.9min\n",
      "[CV 1/5] END ...............C=100, gamma=0.0001;, score=0.791 total time= 1.8min\n",
      "[CV 2/5] END ...............C=100, gamma=0.0001;, score=0.772 total time= 1.8min\n",
      "[CV 3/5] END ...............C=100, gamma=0.0001;, score=0.797 total time= 1.8min\n",
      "[CV 4/5] END ...............C=100, gamma=0.0001;, score=0.780 total time= 1.8min\n",
      "[CV 5/5] END ...............C=100, gamma=0.0001;, score=0.769 total time= 1.7min\n",
      "[CV 1/5] END ..................C=1, gamma=0.001;, score=0.765 total time= 2.3min\n",
      "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.753 total time= 2.2min\n",
      "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.767 total time= 2.3min\n",
      "[CV 4/5] END ..................C=1, gamma=0.001;, score=0.772 total time= 2.5min\n",
      "[CV 5/5] END ..................C=1, gamma=0.001;, score=0.740 total time= 2.3min\n",
      "[CV 1/5] END ....................C=1, gamma=0.1;, score=0.765 total time= 3.0min\n",
      "[CV 2/5] END ....................C=1, gamma=0.1;, score=0.754 total time= 2.9min\n",
      "[CV 3/5] END ....................C=1, gamma=0.1;, score=0.768 total time= 2.9min\n",
      "[CV 4/5] END ....................C=1, gamma=0.1;, score=0.761 total time= 2.9min\n",
      "[CV 5/5] END ....................C=1, gamma=0.1;, score=0.752 total time= 2.9min\n",
      "[CV 1/5] END ....................C=0.1, gamma=1;, score=0.598 total time= 3.2min\n",
      "[CV 2/5] END ....................C=0.1, gamma=1;, score=0.598 total time= 3.1min\n",
      "[CV 3/5] END ....................C=0.1, gamma=1;, score=0.598 total time= 3.2min\n",
      "[CV 4/5] END ....................C=0.1, gamma=1;, score=0.598 total time= 3.1min\n",
      "[CV 5/5] END ....................C=0.1, gamma=1;, score=0.598 total time= 3.1min\n",
      "[CV 1/5] END ...............C=0.1, gamma=0.0001;, score=0.598 total time= 2.8min\n",
      "[CV 2/5] END ...............C=0.1, gamma=0.0001;, score=0.598 total time= 2.7min\n",
      "[CV 3/5] END ...............C=0.1, gamma=0.0001;, score=0.598 total time= 2.7min\n",
      "[CV 4/5] END ...............C=0.1, gamma=0.0001;, score=0.598 total time= 2.8min\n",
      "[CV 5/5] END ...............C=0.1, gamma=0.0001;, score=0.598 total time= 2.4min\n",
      "[CV 1/5] END ..............C=1000, gamma=0.0001;, score=0.782 total time= 1.4min\n",
      "[CV 2/5] END ..............C=1000, gamma=0.0001;, score=0.732 total time= 1.4min\n",
      "[CV 3/5] END ..............C=1000, gamma=0.0001;, score=0.790 total time= 1.4min\n",
      "[CV 4/5] END ..............C=1000, gamma=0.0001;, score=0.770 total time= 1.4min\n",
      "[CV 5/5] END ..............C=1000, gamma=0.0001;, score=0.755 total time= 1.4min\n",
      "39/39 [==============================] - 0s 8ms/step\n",
      "78/78 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n",
      "100%|██████████| 9861/9861 [00:05<00:00, 1791.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.871 total time= 2.2min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.850 total time= 1.9min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.887 total time= 1.9min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.886 total time= 2.4min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.850 total time= 1.8min\n",
      "[16:05:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  20.9s\n",
      "[16:05:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  21.2s\n",
      "[16:06:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  20.8s\n",
      "[16:06:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  19.6s\n",
      "[16:06:41] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  19.4s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.868 total time= 2.6min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.847 total time= 2.2min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.884 total time= 2.4min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.885 total time= 2.2min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.852 total time= 2.4min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.876 total time= 6.8min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.859 total time= 7.5min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.889 total time= 7.3min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.894 total time= 7.7min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.863 total time= 7.6min\n",
      "[16:55:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  17.1s\n",
      "[16:55:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  17.9s\n",
      "[16:56:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  24.7s\n",
      "[16:56:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  27.1s\n",
      "[16:57:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  26.2s\n",
      "[16:57:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  16.7s\n",
      "[16:57:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  19.8s\n",
      "[16:58:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  22.3s\n",
      "[16:58:25] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  22.4s\n",
      "[16:58:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  16.8s\n",
      "[16:59:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  20.0s\n",
      "[16:59:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  17.9s\n",
      "[16:59:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  19.4s\n",
      "[17:00:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  19.5s\n",
      "[17:00:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  20.5s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.870 total time= 3.1min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.847 total time= 3.2min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.886 total time= 3.4min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.885 total time= 3.1min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.852 total time= 3.5min\n",
      "[17:16:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  16.0s\n",
      "[17:17:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  24.2s\n",
      "[17:17:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  12.3s\n",
      "[17:17:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  16.2s\n",
      "[17:18:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  24.8s\n",
      "[17:18:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  22.0s\n",
      "[17:18:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  21.2s\n",
      "[17:19:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  23.6s\n",
      "[17:19:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  22.5s\n",
      "[17:19:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  21.8s\n",
      "[17:20:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  16.5s\n",
      "[17:20:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  19.7s\n",
      "[17:20:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  20.0s\n",
      "[17:21:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  19.6s\n",
      "[17:21:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  21.6s\n",
      "[17:21:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  29.3s\n",
      "[17:22:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  34.2s\n",
      "[17:23:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  31.2s\n",
      "[17:23:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  31.4s\n",
      "[17:24:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  31.4s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.867 total time= 2.5min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.848 total time= 2.5min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.887 total time= 2.3min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.886 total time= 2.4min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.855 total time= 2.4min\n",
      "[17:36:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  32.5s\n",
      "[17:37:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  29.1s\n",
      "[17:37:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  27.2s\n",
      "[17:38:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  27.9s\n",
      "[17:38:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=  28.8s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.869 total time= 1.7min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.849 total time= 1.7min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.888 total time= 1.6min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.885 total time= 1.6min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.855 total time= 1.6min\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END ....................C=0.1, gamma=1;, score=0.593 total time= 2.7min\n",
      "[CV 2/5] END ....................C=0.1, gamma=1;, score=0.593 total time= 2.8min\n",
      "[CV 3/5] END ....................C=0.1, gamma=1;, score=0.593 total time= 2.7min\n",
      "[CV 4/5] END ....................C=0.1, gamma=1;, score=0.593 total time= 2.9min\n",
      "[CV 5/5] END ....................C=0.1, gamma=1;, score=0.593 total time= 2.7min\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.798 total time= 1.5min\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.784 total time= 1.5min\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.813 total time= 1.5min\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.801 total time= 1.5min\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.777 total time= 1.4min\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.593 total time= 2.5min\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.592 total time= 2.5min\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.593 total time= 2.5min\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.593 total time= 2.6min\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.593 total time= 2.7min\n",
      "[CV 1/5] END ................C=100, gamma=0.001;, score=0.785 total time= 1.4min\n",
      "[CV 2/5] END ................C=100, gamma=0.001;, score=0.763 total time= 1.3min\n",
      "[CV 3/5] END ................C=100, gamma=0.001;, score=0.815 total time= 1.3min\n",
      "[CV 4/5] END ................C=100, gamma=0.001;, score=0.791 total time= 1.4min\n",
      "[CV 5/5] END ................C=100, gamma=0.001;, score=0.774 total time= 1.4min\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.798 total time= 1.5min\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.775 total time= 1.5min\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.816 total time= 1.5min\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.787 total time= 1.5min\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.774 total time= 1.4min\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.785 total time= 1.6min\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.762 total time= 1.7min\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.806 total time= 1.7min\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.788 total time= 1.7min\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.767 total time= 1.6min\n",
      "[CV 1/5] END .................C=0.1, gamma=0.01;, score=0.767 total time= 1.9min\n",
      "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.753 total time= 1.9min\n",
      "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.780 total time= 1.9min\n",
      "[CV 4/5] END .................C=0.1, gamma=0.01;, score=0.755 total time= 1.9min\n",
      "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.749 total time= 1.9min\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.786 total time= 1.9min\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=0.767 total time= 1.9min\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.801 total time= 1.9min\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=0.792 total time= 2.0min\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=0.783 total time= 1.9min\n",
      "[CV 1/5] END ...............C=0.1, gamma=0.0001;, score=0.593 total time= 2.1min\n",
      "[CV 2/5] END ...............C=0.1, gamma=0.0001;, score=0.593 total time= 2.1min\n",
      "[CV 3/5] END ...............C=0.1, gamma=0.0001;, score=0.593 total time= 2.1min\n",
      "[CV 4/5] END ...............C=0.1, gamma=0.0001;, score=0.593 total time= 2.1min\n",
      "[CV 5/5] END ...............C=0.1, gamma=0.0001;, score=0.593 total time= 2.1min\n",
      "[CV 1/5] END ....................C=100, gamma=1;, score=0.593 total time= 2.4min\n",
      "[CV 2/5] END ....................C=100, gamma=1;, score=0.592 total time= 2.5min\n",
      "[CV 3/5] END ....................C=100, gamma=1;, score=0.593 total time= 2.4min\n",
      "[CV 4/5] END ....................C=100, gamma=1;, score=0.593 total time= 2.5min\n",
      "[CV 5/5] END ....................C=100, gamma=1;, score=0.593 total time= 2.5min\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.778 total time= 2.4min\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.762 total time= 2.4min\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.800 total time= 2.4min\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.771 total time= 2.4min\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.774 total time= 2.4min\n",
      "[CV 1/5] END ......................C=1, gamma=1;, score=0.593 total time= 2.5min\n",
      "[CV 2/5] END ......................C=1, gamma=1;, score=0.592 total time= 2.7min\n",
      "[CV 3/5] END ......................C=1, gamma=1;, score=0.593 total time= 2.3min\n",
      "[CV 4/5] END ......................C=1, gamma=1;, score=0.593 total time= 2.3min\n",
      "[CV 5/5] END ......................C=1, gamma=1;, score=0.593 total time= 2.4min\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.593 total time= 2.3min\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.592 total time= 2.3min\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.593 total time= 2.6min\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.593 total time= 2.7min\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.593 total time= 2.7min\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.777 total time= 2.5min\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.762 total time= 2.5min\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.800 total time= 2.5min\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.771 total time= 2.5min\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.774 total time= 2.7min\n",
      "[CV 1/5] END .................C=100, gamma=0.01;, score=0.789 total time= 2.1min\n",
      "[CV 2/5] END .................C=100, gamma=0.01;, score=0.767 total time= 2.1min\n",
      "[CV 3/5] END .................C=100, gamma=0.01;, score=0.801 total time= 2.2min\n",
      "[CV 4/5] END .................C=100, gamma=0.01;, score=0.793 total time= 2.1min\n",
      "[CV 5/5] END .................C=100, gamma=0.01;, score=0.783 total time= 2.4min\n",
      "39/39 [==============================] - 0s 4ms/step\n",
      "78/78 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n",
      "100%|██████████| 9861/9861 [00:04<00:00, 2202.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[20:38:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  26.8s\n",
      "[20:38:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  25.9s\n",
      "[20:39:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  26.1s\n",
      "[20:39:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  26.3s\n",
      "[20:39:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  27.3s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.885 total time= 5.1min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.867 total time= 4.9min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.847 total time= 4.9min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.895 total time= 4.9min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.872 total time= 4.7min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.884 total time= 4.2min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.867 total time= 4.3min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.850 total time= 4.2min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.894 total time= 4.3min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.872 total time= 3.9min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=10, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.887 total time= 2.6min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=10, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.866 total time= 2.6min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=10, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.854 total time= 2.9min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=10, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.895 total time= 2.9min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=10, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.877 total time= 2.5min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.889 total time= 4.1min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.868 total time= 3.5min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.849 total time= 3.8min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.897 total time= 3.9min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.877 total time= 3.9min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.868 total time= 1.4min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.858 total time= 1.4min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.842 total time= 1.4min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.884 total time= 1.4min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.866 total time= 1.4min\n",
      "[22:05:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  13.1s\n",
      "[22:05:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  13.2s\n",
      "[22:06:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  13.0s\n",
      "[22:06:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  13.5s\n",
      "[22:06:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  13.6s\n",
      "[22:06:47] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=   6.6s\n",
      "[22:06:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=   6.8s\n",
      "[22:07:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=   6.6s\n",
      "[22:07:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=   6.3s\n",
      "[22:07:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=   6.3s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.879 total time= 2.5min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.865 total time= 2.3min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.851 total time= 2.4min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.891 total time= 2.5min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.870 total time= 1.8min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.889 total time= 1.8min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.868 total time= 1.8min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.849 total time= 1.8min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.895 total time= 1.8min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.874 total time= 1.8min\n",
      "[22:27:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=   5.0s\n",
      "[22:27:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=   4.9s\n",
      "[22:27:54] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=   4.6s\n",
      "[22:27:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=   4.5s\n",
      "[22:28:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=   4.7s\n",
      "[22:28:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=   6.6s\n",
      "[22:28:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=   6.5s\n",
      "[22:28:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=   7.2s\n",
      "[22:28:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=   6.8s\n",
      "[22:28:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=   7.1s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.883 total time= 1.4min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.865 total time= 1.5min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.849 total time= 1.5min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.891 total time= 1.4min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.870 total time= 1.4min\n",
      "[22:35:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   5.7s\n",
      "[22:36:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   5.6s\n",
      "[22:36:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   5.7s\n",
      "[22:36:12] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   5.5s\n",
      "[22:36:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   5.1s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.871 total time=  43.8s\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.858 total time=  43.3s\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.846 total time=  45.6s\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.886 total time=  44.9s\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.871 total time=  41.1s\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.598 total time= 2.9min\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.597 total time= 2.9min\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.597 total time= 2.8min\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.598 total time= 2.9min\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.597 total time= 2.9min\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.797 total time= 1.8min\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.769 total time= 1.7min\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.767 total time= 1.7min\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.797 total time= 1.8min\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.777 total time= 1.8min\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.790 total time= 3.0min\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.766 total time= 2.8min\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.768 total time= 3.0min\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.788 total time= 3.0min\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.775 total time= 3.2min\n",
      "[CV 1/5] END .................C=0.1, gamma=0.01;, score=0.776 total time= 2.4min\n",
      "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.760 total time= 2.4min\n",
      "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.760 total time= 2.5min\n",
      "[CV 4/5] END .................C=0.1, gamma=0.01;, score=0.766 total time= 2.3min\n",
      "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.750 total time= 2.2min\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.598 total time= 2.8min\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.597 total time= 2.8min\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.597 total time= 2.8min\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.598 total time= 2.8min\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.597 total time= 2.8min\n"
     ]
    }
   ],
   "source": [
    "group = admet_group(path = 'data/')\n",
    "\n",
    "pred_valid_list_xgb = []\n",
    "pred_valid_list_rf = []\n",
    "pred_valid_list_svm = []\n",
    "pred_valid_list_adb = []\n",
    "pred_valid_list_cnn = []\n",
    "        \n",
    "pred_test_list_xgb = []\n",
    "pred_test_list_rf = []\n",
    "pred_test_list_svm = []\n",
    "pred_test_list_adb = []\n",
    "pred_test_list_cnn = []\n",
    "\n",
    "best_params_list_xgb = []\n",
    "best_params_list_svm = []\n",
    "\n",
    "for seed in [1, 2, 3, 4, 5]:\n",
    "    pred_valid_xgb = {}\n",
    "    pred_valid_rf = {}\n",
    "    pred_valid_svm = {}\n",
    "    pred_valid_adb = {}\n",
    "    pred_valid_cnn = {}\n",
    "\n",
    "    pred_test_xgb = {}\n",
    "    pred_test_rf = {}\n",
    "    pred_test_svm = {}\n",
    "    pred_test_adb = {}\n",
    "    pred_test_cnn = {}\n",
    "\n",
    "    benchmark = group.get('CYP3A4_Veith')\n",
    "    name = benchmark['name']\n",
    "    train_val, test = benchmark['train_val'], benchmark['test']\n",
    "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)\n",
    "\n",
    "    PandasTools.AddMoleculeColumnToFrame(train, smilesCol='Drug')\n",
    "    radius=2\n",
    "    nBits=1024\n",
    "    ECFP6 = [AllChem.GetMorganFingerprintAsBitVect(x,radius=radius, nBits=nBits) for x in train['ROMol']]\n",
    "    ecfp6_name = [f'Bit_{i}' for i in range(nBits)]\n",
    "    ecfp6_bits = [list(l) for l in ECFP6]\n",
    "    Y = train['Y']\n",
    "    train = pd.DataFrame(ecfp6_bits, index = train.Drug, columns=ecfp6_name).reset_index(drop = False)\n",
    "    train['Y'] = Y\n",
    "\n",
    "    PandasTools.AddMoleculeColumnToFrame(valid, smilesCol='Drug')\n",
    "    radius=2\n",
    "    nBits=1024\n",
    "    ECFP6 = [AllChem.GetMorganFingerprintAsBitVect(x,radius=radius, nBits=nBits) for x in valid['ROMol']]\n",
    "    ecfp6_name = [f'Bit_{i}' for i in range(nBits)]\n",
    "    ecfp6_bits = [list(l) for l in ECFP6]\n",
    "    Y = valid['Y']\n",
    "    valid = pd.DataFrame(ecfp6_bits, index = valid.Drug, columns=ecfp6_name).reset_index(drop = False)\n",
    "    valid['Y'] = Y\n",
    "\n",
    "    PandasTools.AddMoleculeColumnToFrame(benchmark['test'], smilesCol='Drug')\n",
    "    radius=2\n",
    "    nBits=1024\n",
    "    ECFP6 = [AllChem.GetMorganFingerprintAsBitVect(x,radius=radius, nBits=nBits) for x in benchmark['test']['ROMol']]\n",
    "    ecfp6_name = [f'Bit_{i}' for i in range(nBits)]\n",
    "    ecfp6_bits = [list(l) for l in ECFP6]\n",
    "    Y = benchmark['test']['Y']\n",
    "    benchmark['test'] = pd.DataFrame(ecfp6_bits, index = benchmark['test'].Drug, columns=ecfp6_name).reset_index(drop = False)\n",
    "    benchmark['test']['Y'] = Y\n",
    "\n",
    "    train_X = train.drop(columns = [\"Drug\",\"Y\"])\n",
    "    train_y = train.Y\n",
    "    valid_X = valid.drop(columns = [\"Drug\",\"Y\"])\n",
    "    globals()['valid_y_%s'%seed] = valid.Y\n",
    "    test_X = benchmark['test'].drop(columns = [\"Drug\",\"Y\"])\n",
    "    test_y = benchmark['test'].Y\n",
    "\n",
    "\n",
    "    #XGBoost + Morgan\n",
    "    xgb_parameters = {'objective':['binary:logistic'],\n",
    "    'booster':['gbtree','gblinear'],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [7,10,15,20],\n",
    "    'min_child_weight': [10,15,20,25],\n",
    "    'colsample_bytree': [0.8, 0.9, 1],\n",
    "    'n_estimators': [300,400,500,600],\n",
    "    \"reg_alpha\"   : [0.5,0.2,1],\n",
    "    \"reg_lambda\"  : [2,3,5],\n",
    "    \"gamma\"       : [1,2,3]}\n",
    "\n",
    "    xgb_model = XGBClassifier()\n",
    "    grid_obj_xgb = RandomizedSearchCV(xgb_model, xgb_parameters, cv=5, n_iter=15, scoring = 'roc_auc', verbose=5, n_jobs=1)\n",
    "    grid_obj_xgb.fit(train_X, train_y, verbose = 1)\n",
    "    y_pred_valid_xgb = grid_obj_xgb.predict_proba(valid_X)\n",
    "    y_pred_test_xgb = grid_obj_xgb.predict_proba(test_X)\n",
    "    pred_valid_xgb[name] = pred_prob_to_score(y_pred_valid_xgb)\n",
    "    pred_valid_list_xgb.append(pred_valid_xgb)\n",
    "    pred_test_xgb[name] = pred_prob_to_score(y_pred_test_xgb)\n",
    "    pred_test_list_xgb.append(pred_test_xgb)\n",
    "    bp_xgb = grid_obj_xgb.best_params_\n",
    "    best_params_list_xgb.append(bp_xgb)\n",
    "\n",
    "    #Random Forest + Morgan\n",
    "    rf_model = RandomForestClassifier()\n",
    "    rf_model.fit(train_X, train_y)\n",
    "    y_pred_valid_rf = rf_model.predict_proba(valid_X)\n",
    "    y_pred_test_rf = rf_model.predict_proba(test_X)\n",
    "    pred_valid_rf[name] = pred_prob_to_score(y_pred_valid_rf)\n",
    "    pred_valid_list_rf.append(pred_valid_rf)\n",
    "    pred_test_rf[name] = pred_prob_to_score(y_pred_test_rf)\n",
    "    pred_test_list_rf.append(pred_test_rf)\n",
    "\n",
    "    #SVM + Morgan\n",
    "    svm_parameters = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "    }\n",
    "    svm_model = SVC(kernel=\"rbf\", probability=True)\n",
    "    grid_obj_svm = RandomizedSearchCV(svm_model, svm_parameters, cv=5, n_iter=15, verbose=5, n_jobs=1)\n",
    "    grid_obj_svm.fit(train_X, train_y)\n",
    "    y_pred_valid_svm = grid_obj_svm.predict_proba(valid_X)\n",
    "    y_pred_test_svm = grid_obj_svm.predict_proba(test_X)\n",
    "    pred_valid_svm[name] = pred_prob_to_score(y_pred_valid_svm)\n",
    "    pred_valid_list_svm.append(pred_valid_svm)\n",
    "    pred_test_svm[name] = pred_prob_to_score(y_pred_test_svm)\n",
    "    pred_test_list_svm.append(pred_test_svm)\n",
    "    bp_svm = grid_obj_svm.best_params_\n",
    "    best_params_list_svm.append(bp_svm)\n",
    "\n",
    "    # AdaBoost + Morgan\n",
    "    DTC = DecisionTreeClassifier(max_depth=4)\n",
    "    adb_model = AdaBoostClassifier(n_estimators=300, base_estimator=DTC, learning_rate=1)\n",
    "    adb_model.fit(train_X, train_y)\n",
    "    y_pred_valid_adb = adb_model.predict_proba(valid_X)\n",
    "    y_pred_test_adb = adb_model.predict_proba(test_X)\n",
    "    pred_valid_adb[name] = pred_prob_to_score(y_pred_valid_adb)\n",
    "    pred_valid_list_adb.append(pred_valid_adb)\n",
    "    pred_test_adb[name] = pred_prob_to_score(y_pred_test_adb)\n",
    "    pred_test_list_adb.append(pred_test_adb)\n",
    "\n",
    "    #CNN + Morgan\n",
    "    train_X_cnn = train_X.to_numpy()\n",
    "    valid_X_cnn = valid_X.to_numpy()\n",
    "    test_X_cnn = test_X.to_numpy()\n",
    "    train_X_cnn = train_X_cnn.reshape(train_X_cnn.shape[0], train_X_cnn.shape[1], 1)\n",
    "    valid_X_cnn = valid_X_cnn.reshape(valid_X_cnn.shape[0], valid_X_cnn.shape[1], 1)\n",
    "    test_X_cnn = test_X_cnn.reshape(test_X_cnn.shape[0], test_X_cnn.shape[1], 1)\n",
    "    train_X = train_X.astype('float32')\n",
    "    valid_X = valid_X.astype('float32')\n",
    "    test_X = test_X.astype('float32')\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(32, 2, padding=\"valid\", activation=\"relu\", input_shape=(1024,1)))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(64, activation=\"relu\"))\n",
    "    cnn_model.add(Dense(1,activation='sigmoid'))\n",
    "    cnn_model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=\"adam\", metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.FalseNegatives()])\n",
    "    cnn_model.fit(train_X_cnn, train_y, batch_size=12, epochs=10, verbose=0)\n",
    "    y_pred_valid_cnn = cnn_model.predict(valid_X_cnn)\n",
    "    y_pred_test_cnn = cnn_model.predict(test_X_cnn)\n",
    "    y_pred_valid_cnn_copy = []\n",
    "    for i in range(len(y_pred_valid_cnn)):\n",
    "        y_pred_valid_cnn_copy.append(y_pred_valid_cnn[i][0])\n",
    "    y_pred_test_cnn_copy = []\n",
    "    for i in range(len(y_pred_test_cnn)):\n",
    "        y_pred_test_cnn_copy.append(y_pred_test_cnn[i][0])\n",
    "    pred_valid_cnn[name] = np.array(y_pred_valid_cnn_copy)\n",
    "    pred_valid_list_cnn.append(pred_valid_cnn)\n",
    "    pred_test_cnn[name] = np.array(y_pred_test_cnn_copy)\n",
    "    pred_test_list_cnn.append(pred_test_cnn)\n",
    "\n",
    "xgb_perform = group.evaluate_many(pred_test_list_xgb)\n",
    "rf_perform = group.evaluate_many(pred_test_list_rf)\n",
    "svm_perform = group.evaluate_many(pred_test_list_svm)\n",
    "adb_perform = group.evaluate_many(pred_test_list_adb)\n",
    "cnn_perform = group.evaluate_many(pred_test_list_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"xgb_perform:\", xgb_perform, \"\\n rf_perform:\", rf_perform, \"\\n svm_perform:\", svm_perform, \"\\n adb_perform:\", adb_perform, \"\\n cnn_perform:\", cnn_perform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = benchmark['test'].Y\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_object(array): # convert scores into ranks\n",
    "    arg_a = np.argsort(array)\n",
    "    b = np.flip(np.arange(len(arg_a)))\n",
    "    a = np.zeros_like(arg_a)\n",
    "    for i in range(len(arg_a)):\n",
    "        a[arg_a[i]] = b[i]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_rank(array):\n",
    "  res = np.argsort(np.flip(np.argsort(array)))+1\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array): # define function for normalization of scores\n",
    "    maximum = np.max(array)\n",
    "    minimum = np.min(array)\n",
    "    norm_list = []\n",
    "    for i in range(len(array)):\n",
    "        norm_list.append((array[i]-minimum)/(maximum-minimum))\n",
    "    return np.array(norm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_valid_xgb = []\n",
    "predictions_valid_rf = []\n",
    "predictions_valid_svm = []\n",
    "predictions_valid_adb = []\n",
    "predictions_valid_cnn = []\n",
    "\n",
    "predictions_test_xgb = []\n",
    "predictions_test_rf = []\n",
    "predictions_test_svm = []\n",
    "predictions_test_adb = []\n",
    "predictions_test_cnn = []\n",
    "\n",
    "scoreSys = ['xgb', 'rf', 'svm', 'adb', 'cnn']\n",
    "\n",
    "for sys in scoreSys:\n",
    "  for seed in range(len(globals()['pred_valid_list_%s' % sys])):\n",
    "    globals()['predictions_valid_%s' % sys].append(list(globals()['pred_valid_list_%s' % sys][seed].values())[0])\n",
    "\n",
    "for sys in scoreSys:\n",
    "  for seed in range(len(globals()['pred_test_list_%s' % sys])):\n",
    "    globals()['predictions_test_%s' % sys].append(list(globals()['pred_test_list_%s' % sys][seed].values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSC graphs\n",
    "colors = ['r--', 'm--', 'b--', 'g--', 'y--']\n",
    "\n",
    "for seed in range(len(globals()['predictions_valid_%s' % sys])):\n",
    "  ranks = np.flip(np.arange(len(predictions_valid_xgb[seed])))\n",
    "  fig, ax = plt.subplots()\n",
    "  for z in range(len(scoreSys)):\n",
    "    globals()['line%s' % (z+1)] = plt.plot(ranks, np.sort(normalize(globals()['predictions_valid_%s' % scoreSys[z]][seed])), colors[z], label = scoreSys[z])\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.title('RSC Graphs of Base Models - Seed %s' % str(seed+1))\n",
    "    plt.xlabel('Rank Value')\n",
    "    plt.ylabel('Normalized Score')\n",
    "  plt.show()\n",
    "  image_name = benchmark['name'] + '_morgan_rsc_seed_%s'% str(seed+1) + '.png'\n",
    "  image_format = 'png'\n",
    "  fig.savefig(image_name, format=image_format, dpi=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_score = [[] for _ in range(5)]\n",
    "for sys in scoreSys:\n",
    "  for seed in range(len(ds_score)):\n",
    "    loc = scoreSys.index(sys)\n",
    "    scoreSys.remove(sys)\n",
    "    ds = 0\n",
    "    for i in range(len(scoreSys)):\n",
    "      ds += np.sum(np.square(normalize(np.sort(globals()['predictions_valid_%s' % sys][seed]))-normalize(np.sort(globals()['predictions_valid_%s' % scoreSys[i]][seed]))))\n",
    "    ds = ds/len(scoreSys)\n",
    "    scoreSys.insert(loc, sys)\n",
    "    ds_score[seed].append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rank = np.reciprocal(ds_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdc import Evaluator\n",
    "def get_auprc(y_pred_proba, y_true):\n",
    "  evaluator = Evaluator(name = 'PR-AUC')\n",
    "  res = evaluator(y_true, y_pred_proba)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score = [[] for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sys in scoreSys:\n",
    "  for seed in range(len(ps_score)):\n",
    "    ps = get_auprc(globals()['predictions_valid_%s' % sys][seed], globals()['valid_y_%s'%str(seed+1)])\n",
    "    ps_score[seed].append(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(s):\n",
    "    x = len(s)\n",
    "    ls = []\n",
    "    for i in range(1 << x):\n",
    "        ls.append([s[j] for j in range(x) if (i & (1 << j))])\n",
    "    return ls[1:]\n",
    "\n",
    "models = powerset(scoreSys)\n",
    "\n",
    "def myFunc(e):\n",
    "  return len(e)\n",
    "\n",
    "models.sort(key=myFunc)\n",
    "\n",
    "models_list = []\n",
    "for i in range(len(models)):\n",
    "  if len(models[i]) == 1:\n",
    "    models_list.append(models[i][0])\n",
    "  elif len(models[i]) == 2:\n",
    "    models_list.append(models[i][0]+'&'+models[i][1])\n",
    "  elif len(models[i]) == 3:\n",
    "    models_list.append(models[i][0]+'&'+models[i][1]+'&'+models[i][2])\n",
    "  elif len(models[i]) == 4:\n",
    "    models_list.append(models[i][0]+'&'+models[i][1]+'&'+models[i][2]+'&'+models[i][3])\n",
    "  elif len(models[i]) == 5:\n",
    "    models_list.append(models[i][0]+'&'+models[i][1]+'&'+models[i][2]+'&'+models[i][3]+'&'+models[i][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform average score combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_combine_seed1 = pd.DataFrame({'xgb':predictions_test_xgb[0], 'rf':predictions_test_rf[0], 'svm':predictions_test_svm[0], 'adb':predictions_test_adb[0], 'cnn':predictions_test_cnn[0]})\n",
    "avg_score_combine_seed2 = pd.DataFrame({'xgb':predictions_test_xgb[1], 'rf':predictions_test_rf[1], 'svm':predictions_test_svm[1], 'adb':predictions_test_adb[1], 'cnn':predictions_test_cnn[1]})\n",
    "avg_score_combine_seed3 = pd.DataFrame({'xgb':predictions_test_xgb[2], 'rf':predictions_test_rf[2], 'svm':predictions_test_svm[2], 'adb':predictions_test_adb[2], 'cnn':predictions_test_cnn[2]})\n",
    "avg_score_combine_seed4 = pd.DataFrame({'xgb':predictions_test_xgb[3], 'rf':predictions_test_rf[3], 'svm':predictions_test_svm[3], 'adb':predictions_test_adb[3], 'cnn':predictions_test_cnn[3]})\n",
    "avg_score_combine_seed5 = pd.DataFrame({'xgb':predictions_test_xgb[4], 'rf':predictions_test_rf[4], 'svm':predictions_test_svm[4], 'adb':predictions_test_adb[4], 'cnn':predictions_test_cnn[4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score_combine(models_list, single_score):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      single_score[j] = (single_score[j.split('&')[0]]+single_score[j.split('&')[1]]) / 2\n",
    "    elif len(j.split('&')) == 3:\n",
    "      single_score[j] = (single_score[j.split('&')[0]]+single_score[j.split('&')[1]]+single_score[j.split('&')[2]]) / 3\n",
    "    elif len(j.split('&')) == 4:\n",
    "      single_score[j] = (single_score[j.split('&')[0]]+single_score[j.split('&')[1]]+single_score[j.split('&')[2]]+single_score[j.split('&')[3]]) / 4\n",
    "    elif len(j.split('&')) == 5:\n",
    "      single_score[j] = (single_score[j.split('&')[0]]+single_score[j.split('&')[1]]+single_score[j.split('&')[2]]+single_score[j.split('&')[3]]+single_score[j.split('&')[4]]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_combine(models_list, avg_score_combine_seed1)\n",
    "avg_score_combine(models_list, avg_score_combine_seed2)\n",
    "avg_score_combine(models_list, avg_score_combine_seed3)\n",
    "avg_score_combine(models_list, avg_score_combine_seed4)\n",
    "avg_score_combine(models_list, avg_score_combine_seed5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform average rank combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_rank(array):\n",
    "  res = np.argsort(np.flip(np.argsort(array)))+1\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rank_combine_seed1 = pd.DataFrame({'xgb':score_to_rank(predictions_test_xgb[0]), 'rf':score_to_rank(predictions_test_rf[0]), 'svm':score_to_rank(predictions_test_svm[0]), 'adb':score_to_rank(predictions_test_adb[0]), 'cnn':score_to_rank(predictions_test_cnn[0])})\n",
    "avg_rank_combine_seed2 = pd.DataFrame({'xgb':score_to_rank(predictions_test_xgb[1]), 'rf':score_to_rank(predictions_test_rf[1]), 'svm':score_to_rank(predictions_test_svm[1]), 'adb':score_to_rank(predictions_test_adb[1]), 'cnn':score_to_rank(predictions_test_cnn[1])})\n",
    "avg_rank_combine_seed3 = pd.DataFrame({'xgb':score_to_rank(predictions_test_xgb[2]), 'rf':score_to_rank(predictions_test_rf[2]), 'svm':score_to_rank(predictions_test_svm[2]), 'adb':score_to_rank(predictions_test_adb[2]), 'cnn':score_to_rank(predictions_test_cnn[2])})\n",
    "avg_rank_combine_seed4 = pd.DataFrame({'xgb':score_to_rank(predictions_test_xgb[3]), 'rf':score_to_rank(predictions_test_rf[3]), 'svm':score_to_rank(predictions_test_svm[3]), 'adb':score_to_rank(predictions_test_adb[3]), 'cnn':score_to_rank(predictions_test_cnn[3])})\n",
    "avg_rank_combine_seed5 = pd.DataFrame({'xgb':score_to_rank(predictions_test_xgb[4]), 'rf':score_to_rank(predictions_test_rf[4]), 'svm':score_to_rank(predictions_test_svm[4]), 'adb':score_to_rank(predictions_test_adb[4]), 'cnn':score_to_rank(predictions_test_cnn[4])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_rank_combine(models_list, single_rank):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      single_rank[j+'_r'] = (single_rank[j.split('&')[0]]+single_rank[j.split('&')[1]]) / 2\n",
    "    elif len(j.split('&')) == 3:\n",
    "      single_rank[j+'_r'] = (single_rank[j.split('&')[0]]+single_rank[j.split('&')[1]]+single_rank[j.split('&')[2]]) / 3\n",
    "    elif len(j.split('&')) == 4:\n",
    "      single_rank[j+'_r'] = (single_rank[j.split('&')[0]]+single_rank[j.split('&')[1]]+single_rank[j.split('&')[2]]+single_rank[j.split('&')[3]]) / 4\n",
    "    elif len(j.split('&')) == 5:\n",
    "      single_rank[j+'_r'] = (single_rank[j.split('&')[0]]+single_rank[j.split('&')[1]]+single_rank[j.split('&')[2]]+single_rank[j.split('&')[3]]+single_rank[j.split('&')[4]]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rank_combine(models_list, avg_rank_combine_seed1)\n",
    "avg_rank_combine(models_list, avg_rank_combine_seed2)\n",
    "avg_rank_combine(models_list, avg_rank_combine_seed3)\n",
    "avg_rank_combine(models_list, avg_rank_combine_seed4)\n",
    "avg_rank_combine(models_list, avg_rank_combine_seed5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform weighted score combination by diversity strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_score_combine_seed1 = pd.DataFrame()\n",
    "ds_score_combine_seed2 = pd.DataFrame()\n",
    "ds_score_combine_seed3 = pd.DataFrame()\n",
    "ds_score_combine_seed4 = pd.DataFrame()\n",
    "ds_score_combine_seed5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_score_combine(models_list, single_score, ds_score_combine, ds_score):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      ds_score_combine[j+'_ds'] = (single_score[j.split('&')[0]]*ds_score[scoreSys.index(j.split('&')[0])]+single_score[j.split('&')[1]]*ds_score[scoreSys.index(j.split('&')[1])])/(ds_score[scoreSys.index(j.split('&')[0])] + ds_score[scoreSys.index(j.split('&')[1])])\n",
    "    elif len(j.split('&')) == 3:\n",
    "      ds_score_combine[j+'_ds'] = (single_score[j.split('&')[0]]*ds_score[scoreSys.index(j.split('&')[0])]+single_score[j.split('&')[1]]*ds_score[scoreSys.index(j.split('&')[1])]+single_score[j.split('&')[2]]*ds_score[scoreSys.index(j.split('&')[2])])/(ds_score[scoreSys.index(j.split('&')[0])] + ds_score[scoreSys.index(j.split('&')[1])] + ds_score[scoreSys.index(j.split('&')[2])])\n",
    "    elif len(j.split('&')) == 4:\n",
    "      ds_score_combine[j+'_ds'] = (single_score[j.split('&')[0]]*ds_score[scoreSys.index(j.split('&')[0])]+single_score[j.split('&')[1]]*ds_score[scoreSys.index(j.split('&')[1])]+single_score[j.split('&')[2]]*ds_score[scoreSys.index(j.split('&')[2])]+single_score[j.split('&')[3]]*ds_score[scoreSys.index(j.split('&')[3])])/(ds_score[scoreSys.index(j.split('&')[0])] + ds_score[scoreSys.index(j.split('&')[1])] + ds_score[scoreSys.index(j.split('&')[2])] + ds_score[scoreSys.index(j.split('&')[3])])\n",
    "    elif len(j.split('&')) == 5:\n",
    "      ds_score_combine[j+'_ds'] = (single_score[j.split('&')[0]]*ds_score[scoreSys.index(j.split('&')[0])]+single_score[j.split('&')[1]]*ds_score[scoreSys.index(j.split('&')[1])]+single_score[j.split('&')[2]]*ds_score[scoreSys.index(j.split('&')[2])]+single_score[j.split('&')[3]]*ds_score[scoreSys.index(j.split('&')[3])]+single_score[j.split('&')[4]]*ds_score[scoreSys.index(j.split('&')[4])])/(ds_score[scoreSys.index(j.split('&')[0])] + ds_score[scoreSys.index(j.split('&')[1])] + ds_score[scoreSys.index(j.split('&')[2])] + ds_score[scoreSys.index(j.split('&')[3])] + ds_score[scoreSys.index(j.split('&')[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_score_combine(models_list, avg_score_combine_seed1, ds_score_combine_seed1, ds_score[0])\n",
    "ds_score_combine(models_list, avg_score_combine_seed2, ds_score_combine_seed2, ds_score[1])\n",
    "ds_score_combine(models_list, avg_score_combine_seed3, ds_score_combine_seed3, ds_score[2])\n",
    "ds_score_combine(models_list, avg_score_combine_seed4, ds_score_combine_seed4, ds_score[3])\n",
    "ds_score_combine(models_list, avg_score_combine_seed5, ds_score_combine_seed5, ds_score[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform weighted rank combination by diversity strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rank_combine_seed1 = pd.DataFrame()\n",
    "ds_rank_combine_seed2 = pd.DataFrame()\n",
    "ds_rank_combine_seed3 = pd.DataFrame()\n",
    "ds_rank_combine_seed4 = pd.DataFrame()\n",
    "ds_rank_combine_seed5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_rank_combine(models_list, single_rank, ds_rank_combine, ds_rank):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      ds_rank_combine[j+'_ds_r'] = (single_rank[j.split('&')[0]]*ds_rank[scoreSys.index(j.split('&')[0])]+single_rank[j.split('&')[1]]*ds_rank[scoreSys.index(j.split('&')[1])])/(ds_rank[scoreSys.index(j.split('&')[0])] + ds_rank[scoreSys.index(j.split('&')[1])])\n",
    "    elif len(j.split('&')) == 3:\n",
    "      ds_rank_combine[j+'_ds_r'] = (single_rank[j.split('&')[0]]*ds_rank[scoreSys.index(j.split('&')[0])]+single_rank[j.split('&')[1]]*ds_rank[scoreSys.index(j.split('&')[1])]+single_rank[j.split('&')[2]]*ds_rank[scoreSys.index(j.split('&')[2])])/(ds_rank[scoreSys.index(j.split('&')[0])] + ds_rank[scoreSys.index(j.split('&')[1])] + ds_rank[scoreSys.index(j.split('&')[2])])\n",
    "    elif len(j.split('&')) == 4:\n",
    "      ds_rank_combine[j+'_ds_r'] = (single_rank[j.split('&')[0]]*ds_rank[scoreSys.index(j.split('&')[0])]+single_rank[j.split('&')[1]]*ds_rank[scoreSys.index(j.split('&')[1])]+single_rank[j.split('&')[2]]*ds_rank[scoreSys.index(j.split('&')[2])]+single_rank[j.split('&')[3]]*ds_rank[scoreSys.index(j.split('&')[3])])/(ds_rank[scoreSys.index(j.split('&')[0])] + ds_rank[scoreSys.index(j.split('&')[1])] + ds_rank[scoreSys.index(j.split('&')[2])] + ds_rank[scoreSys.index(j.split('&')[3])])\n",
    "    elif len(j.split('&')) == 5:\n",
    "      ds_rank_combine[j+'_ds_r'] = (single_rank[j.split('&')[0]]*ds_rank[scoreSys.index(j.split('&')[0])]+single_rank[j.split('&')[1]]*ds_rank[scoreSys.index(j.split('&')[1])]+single_rank[j.split('&')[2]]*ds_rank[scoreSys.index(j.split('&')[2])]+single_rank[j.split('&')[3]]*ds_rank[scoreSys.index(j.split('&')[3])]+single_rank[j.split('&')[4]]*ds_rank[scoreSys.index(j.split('&')[4])])/(ds_rank[scoreSys.index(j.split('&')[0])] + ds_rank[scoreSys.index(j.split('&')[1])] + ds_rank[scoreSys.index(j.split('&')[2])] + ds_rank[scoreSys.index(j.split('&')[3])] + ds_rank[scoreSys.index(j.split('&')[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rank_combine(models_list, avg_rank_combine_seed1, ds_rank_combine_seed1, ds_rank[0])\n",
    "ds_rank_combine(models_list, avg_rank_combine_seed2, ds_rank_combine_seed2, ds_rank[1])\n",
    "ds_rank_combine(models_list, avg_rank_combine_seed3, ds_rank_combine_seed3, ds_rank[2])\n",
    "ds_rank_combine(models_list, avg_rank_combine_seed4, ds_rank_combine_seed4, ds_rank[3])\n",
    "ds_rank_combine(models_list, avg_rank_combine_seed5, ds_rank_combine_seed5, ds_rank[4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform weighted score combination by performance strength (AUPRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score_combine_seed1 = pd.DataFrame()\n",
    "ps_score_combine_seed2 = pd.DataFrame()\n",
    "ps_score_combine_seed3 = pd.DataFrame()\n",
    "ps_score_combine_seed4 = pd.DataFrame()\n",
    "ps_score_combine_seed5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps_score_combine(models_list, single_score, ps_score_combine, ps_score):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      ps_score_combine[j+'_ps'] = (single_score[j.split('&')[0]]*(ps_score[scoreSys.index(j.split('&')[0])])+single_score[j.split('&')[1]]*(ps_score[scoreSys.index(j.split('&')[1])]))/(ps_score[scoreSys.index(j.split('&')[0])] + ps_score[scoreSys.index(j.split('&')[1])])\n",
    "    elif len(j.split('&')) == 3:\n",
    "      ps_score_combine[j+'_ps'] = (single_score[j.split('&')[0]]*(ps_score[scoreSys.index(j.split('&')[0])])+single_score[j.split('&')[1]]*(ps_score[scoreSys.index(j.split('&')[1])])+single_score[j.split('&')[2]]*(ps_score[scoreSys.index(j.split('&')[2])]))/(ps_score[scoreSys.index(j.split('&')[0])] + ps_score[scoreSys.index(j.split('&')[1])] + ps_score[scoreSys.index(j.split('&')[2])])\n",
    "    elif len(j.split('&')) == 4:\n",
    "      ps_score_combine[j+'_ps'] = (single_score[j.split('&')[0]]*(ps_score[scoreSys.index(j.split('&')[0])])+single_score[j.split('&')[1]]*(ps_score[scoreSys.index(j.split('&')[1])])+single_score[j.split('&')[2]]*(ps_score[scoreSys.index(j.split('&')[2])])+single_score[j.split('&')[3]]*(ps_score[scoreSys.index(j.split('&')[3])]))/(ps_score[scoreSys.index(j.split('&')[0])] + ps_score[scoreSys.index(j.split('&')[1])] + ps_score[scoreSys.index(j.split('&')[2])] + ps_score[scoreSys.index(j.split('&')[3])])\n",
    "    elif len(j.split('&')) == 5:\n",
    "      ps_score_combine[j+'_ps'] = (single_score[j.split('&')[0]]*(ps_score[scoreSys.index(j.split('&')[0])])+single_score[j.split('&')[1]]*(ps_score[scoreSys.index(j.split('&')[1])])+single_score[j.split('&')[2]]*(ps_score[scoreSys.index(j.split('&')[2])])+single_score[j.split('&')[3]]*(ps_score[scoreSys.index(j.split('&')[3])])+single_score[j.split('&')[4]]*(ps_score[scoreSys.index(j.split('&')[4])]))/(ps_score[scoreSys.index(j.split('&')[0])] + ps_score[scoreSys.index(j.split('&')[1])] + ps_score[scoreSys.index(j.split('&')[2])] + ps_score[scoreSys.index(j.split('&')[3])] + ps_score[scoreSys.index(j.split('&')[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score_combine(models_list, avg_score_combine_seed1, ps_score_combine_seed1, ps_score[0])\n",
    "ps_score_combine(models_list, avg_score_combine_seed2, ps_score_combine_seed2, ps_score[1])\n",
    "ps_score_combine(models_list, avg_score_combine_seed3, ps_score_combine_seed3, ps_score[2])\n",
    "ps_score_combine(models_list, avg_score_combine_seed4, ps_score_combine_seed4, ps_score[3])\n",
    "ps_score_combine(models_list, avg_score_combine_seed5, ps_score_combine_seed5, ps_score[4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform weighted rank combination by performance strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_rank_combine_seed1 = pd.DataFrame()\n",
    "ps_rank_combine_seed2 = pd.DataFrame()\n",
    "ps_rank_combine_seed3 = pd.DataFrame()\n",
    "ps_rank_combine_seed4 = pd.DataFrame()\n",
    "ps_rank_combine_seed5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps_rank_combine(models_list, single_rank, ps_rank_combine, ps_score):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      ps_rank_combine[j+'_ps_r'] = (single_rank[j.split('&')[0]]*(1 / ps_score[scoreSys.index(j.split('&')[0])])+single_rank[j.split('&')[1]]*(1 / ps_score[scoreSys.index(j.split('&')[1])]))/(1 / ps_score[scoreSys.index(j.split('&')[0])] + 1 / ps_score[scoreSys.index(j.split('&')[1])])\n",
    "    elif len(j.split('&')) == 3:\n",
    "      ps_rank_combine[j+'_ps_r'] = (single_rank[j.split('&')[0]]*(1 / ps_score[scoreSys.index(j.split('&')[0])])+single_rank[j.split('&')[1]]*(1 / ps_score[scoreSys.index(j.split('&')[1])])+single_rank[j.split('&')[2]]*(1 / ps_score[scoreSys.index(j.split('&')[2])]))/(1 / ps_score[scoreSys.index(j.split('&')[0])] + 1 / ps_score[scoreSys.index(j.split('&')[1])] + 1 / ps_score[scoreSys.index(j.split('&')[2])])\n",
    "    elif len(j.split('&')) == 4:\n",
    "      ps_rank_combine[j+'_ps_r'] = (single_rank[j.split('&')[0]]*(1 / ps_score[scoreSys.index(j.split('&')[0])])+single_rank[j.split('&')[1]]*(1 / ps_score[scoreSys.index(j.split('&')[1])])+single_rank[j.split('&')[2]]*(1 / ps_score[scoreSys.index(j.split('&')[2])])+single_rank[j.split('&')[3]]*(1 / ps_score[scoreSys.index(j.split('&')[3])]))/(1 / ps_score[scoreSys.index(j.split('&')[0])] + 1 / ps_score[scoreSys.index(j.split('&')[1])] + 1 / ps_score[scoreSys.index(j.split('&')[2])] + 1 / ps_score[scoreSys.index(j.split('&')[3])])\n",
    "    elif len(j.split('&')) == 5:\n",
    "      ps_rank_combine[j+'_ps_r'] = (single_rank[j.split('&')[0]]*(1 / ps_score[scoreSys.index(j.split('&')[0])])+single_rank[j.split('&')[1]]*(1 / ps_score[scoreSys.index(j.split('&')[1])])+single_rank[j.split('&')[2]]*(1 / ps_score[scoreSys.index(j.split('&')[2])])+single_rank[j.split('&')[3]]*(1 / ps_score[scoreSys.index(j.split('&')[3])])+single_rank[j.split('&')[4]]*(1 / ps_score[scoreSys.index(j.split('&')[4])]))/(1 / ps_score[scoreSys.index(j.split('&')[0])] + 1 / ps_score[scoreSys.index(j.split('&')[1])] + 1 / ps_score[scoreSys.index(j.split('&')[2])] + 1 / ps_score[scoreSys.index(j.split('&')[3])] + 1 / ps_score[scoreSys.index(j.split('&')[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_rank_combine(models_list, avg_rank_combine_seed1, ps_rank_combine_seed1, ps_score[0])\n",
    "ps_rank_combine(models_list, avg_rank_combine_seed2, ps_rank_combine_seed2, ps_score[1])\n",
    "ps_rank_combine(models_list, avg_rank_combine_seed3, ps_rank_combine_seed3, ps_score[2])\n",
    "ps_rank_combine(models_list, avg_rank_combine_seed4, ps_rank_combine_seed4, ps_score[3])\n",
    "ps_rank_combine(models_list, avg_rank_combine_seed5, ps_rank_combine_seed5, ps_score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rank_combine_seed1.rename(columns={'xgb': 'xgb_r', 'rf': 'rf_r', 'svm': 'svm_r', 'adb': 'adb_r', 'cnn': 'cnn_r'}, inplace=True)\n",
    "avg_rank_combine_seed2.rename(columns={'xgb': 'xgb_r', 'rf': 'rf_r', 'svm': 'svm_r', 'adb': 'adb_r', 'cnn': 'cnn_r'}, inplace=True)\n",
    "avg_rank_combine_seed3.rename(columns={'xgb': 'xgb_r', 'rf': 'rf_r', 'svm': 'svm_r', 'adb': 'adb_r', 'cnn': 'cnn_r'}, inplace=True)\n",
    "avg_rank_combine_seed4.rename(columns={'xgb': 'xgb_r', 'rf': 'rf_r', 'svm': 'svm_r', 'adb': 'adb_r', 'cnn': 'cnn_r'}, inplace=True)\n",
    "avg_rank_combine_seed5.rename(columns={'xgb': 'xgb_r', 'rf': 'rf_r', 'svm': 'svm_r', 'adb': 'adb_r', 'cnn': 'cnn_r'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_combine_list = np.hstack((np.array(avg_score_combine_seed1.columns), np.array(ds_score_combine_seed1.columns), np.array(ps_score_combine_seed1.columns)))\n",
    "AUPRC = pd.DataFrame(index = score_combine_list)\n",
    "for i in range(1, 6):\n",
    "  auprc_avg, auprc_ds, auprc_ps = [], [], []\n",
    "  for col in globals()['avg_score_combine_seed%s' %i].columns:\n",
    "    auprc_score = get_auprc(np.array(globals()['avg_score_combine_seed%s' %i][col]), y_test)\n",
    "    auprc_avg.append(auprc_score)\n",
    "  for col in globals()['ds_score_combine_seed%s' %i].columns:\n",
    "    auprc_score = get_auprc(np.array(globals()['ds_score_combine_seed%s' %i][col]), y_test)\n",
    "    auprc_ds.append(auprc_score)\n",
    "  for col in globals()['ps_score_combine_seed%s' %i].columns:\n",
    "    auprc_score = get_auprc(np.array(globals()['ps_score_combine_seed%s' %i][col]), y_test)\n",
    "    auprc_ps.append(auprc_score)\n",
    "  AUPRC['seed'+str(i)] = np.hstack((auprc_avg, auprc_ds, auprc_ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUPRC['avg_AUPRC'] = AUPRC.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUPRC.sort_values(by='avg_AUPRC', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

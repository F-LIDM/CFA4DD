{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/NathanJiang/opt/anaconda3/envs/tf/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2023.03.2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm #progress bar\n",
    "import rdkit\n",
    "from rdkit import Chem #Chemistry\n",
    "from rdkit.Chem import rdMolDescriptors #molecular descriptors\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "rdkit.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 04:18:46.958438: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from sklearn.model_selection import train_test_split #ML training\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from yellowbrick.regressor import prediction_error, ResidualsPlot\n",
    "from tdc.single_pred import ADME\n",
    "from tdc.benchmark_group import admet_group\n",
    "from tdc import BenchmarkGroup\n",
    "from tdc import Evaluator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_prob_to_score(pred_prob):\n",
    "    res = []\n",
    "    for i in range(len(pred_prob)):\n",
    "        res.append(pred_prob[i][1])\n",
    "    res = np.array(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "generating training, validation splits...\n",
      "100%|██████████| 9673/9673 [00:04<00:00, 2034.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[04:19:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  25.8s\n",
      "[04:19:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  24.2s\n",
      "[04:20:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  22.7s\n",
      "[04:20:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  19.9s\n",
      "[04:20:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  17.6s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.819 total time= 1.7min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.875 total time= 1.9min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.852 total time= 1.9min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.839 total time= 1.9min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.857 total time= 1.9min\n",
      "[04:30:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  24.4s\n",
      "[04:30:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  24.0s\n",
      "[04:31:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  23.4s\n",
      "[04:31:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  24.1s\n",
      "[04:32:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  24.2s\n",
      "[04:32:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  24.3s\n",
      "[04:32:51] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  23.3s\n",
      "[04:33:15] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  23.3s\n",
      "[04:33:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  21.2s\n",
      "[04:33:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  20.9s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.838 total time= 5.2min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.873 total time= 5.4min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.856 total time= 6.0min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.848 total time= 6.1min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.864 total time= 6.2min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.839 total time= 8.5min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.875 total time= 8.5min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.855 total time= 9.1min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.850 total time=10.0min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.865 total time= 9.9min\n",
      "[05:49:06] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  22.6s\n",
      "[05:49:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  20.0s\n",
      "[05:49:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  20.9s\n",
      "[05:50:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  20.1s\n",
      "[05:50:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  19.6s\n",
      "[05:50:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  15.4s\n",
      "[05:51:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  17.1s\n",
      "[05:51:22] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  15.7s\n",
      "[05:51:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  14.7s\n",
      "[05:51:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  14.4s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.838 total time= 7.9min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.874 total time= 8.0min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.857 total time= 7.8min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.848 total time= 7.9min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.865 total time= 7.4min\n",
      "[06:31:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  26.0s\n",
      "[06:31:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  27.3s\n",
      "[06:31:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  25.5s\n",
      "[06:32:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  19.2s\n",
      "[06:32:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  18.6s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.838 total time= 4.4min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.875 total time= 3.7min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.856 total time= 4.4min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.848 total time= 3.8min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.864 total time= 2.9min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.829 total time= 2.9min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.875 total time= 2.9min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.859 total time= 2.6min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.842 total time= 2.9min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.860 total time= 3.1min\n",
      "[07:06:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  15.6s\n",
      "[07:06:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  16.6s\n",
      "[07:07:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  17.3s\n",
      "[07:07:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  18.2s\n",
      "[07:07:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  16.7s\n",
      "[07:07:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  35.1s\n",
      "[07:08:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  37.0s\n",
      "[07:09:07] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  42.2s\n",
      "[07:09:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  27.1s\n",
      "[07:10:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=  21.8s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.840 total time= 6.6min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.876 total time= 7.9min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.857 total time= 7.3min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.854 total time= 7.2min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.866 total time= 7.6min\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END ................C=10, gamma=0.0001;, score=0.746 total time= 2.3min\n",
      "[CV 2/5] END ................C=10, gamma=0.0001;, score=0.763 total time= 2.3min\n",
      "[CV 3/5] END ................C=10, gamma=0.0001;, score=0.746 total time= 2.3min\n",
      "[CV 4/5] END ................C=10, gamma=0.0001;, score=0.751 total time= 2.2min\n",
      "[CV 5/5] END ................C=10, gamma=0.0001;, score=0.757 total time= 2.2min\n",
      "[CV 1/5] END ...............C=0.1, gamma=0.0001;, score=0.661 total time= 2.1min\n",
      "[CV 2/5] END ...............C=0.1, gamma=0.0001;, score=0.661 total time= 2.0min\n",
      "[CV 3/5] END ...............C=0.1, gamma=0.0001;, score=0.661 total time= 2.0min\n",
      "[CV 4/5] END ...............C=0.1, gamma=0.0001;, score=0.661 total time= 2.1min\n",
      "[CV 5/5] END ...............C=0.1, gamma=0.0001;, score=0.661 total time= 2.2min\n",
      "[CV 1/5] END ....................C=0.1, gamma=1;, score=0.661 total time= 2.7min\n",
      "[CV 2/5] END ....................C=0.1, gamma=1;, score=0.661 total time= 3.0min\n",
      "[CV 3/5] END ....................C=0.1, gamma=1;, score=0.661 total time= 2.7min\n",
      "[CV 4/5] END ....................C=0.1, gamma=1;, score=0.661 total time= 2.8min\n",
      "[CV 5/5] END ....................C=0.1, gamma=1;, score=0.661 total time= 2.8min\n",
      "[CV 1/5] END .................C=1, gamma=0.0001;, score=0.661 total time= 2.1min\n",
      "[CV 2/5] END .................C=1, gamma=0.0001;, score=0.661 total time= 2.2min\n",
      "[CV 3/5] END .................C=1, gamma=0.0001;, score=0.661 total time= 2.1min\n",
      "[CV 4/5] END .................C=1, gamma=0.0001;, score=0.661 total time= 2.1min\n",
      "[CV 5/5] END .................C=1, gamma=0.0001;, score=0.661 total time= 2.1min\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.661 total time= 2.8min\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.660 total time= 2.8min\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.657 total time= 2.8min\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.661 total time= 2.8min\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.661 total time= 2.8min\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.661 total time= 2.8min\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.660 total time= 2.8min\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.657 total time= 2.7min\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.661 total time= 2.8min\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.661 total time= 2.9min\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.768 total time= 1.8min\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.784 total time= 1.9min\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.755 total time= 1.8min\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.765 total time= 1.8min\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.761 total time= 1.8min\n",
      "[CV 1/5] END .................C=100, gamma=0.01;, score=0.764 total time= 2.2min\n",
      "[CV 2/5] END .................C=100, gamma=0.01;, score=0.791 total time= 2.3min\n",
      "[CV 3/5] END .................C=100, gamma=0.01;, score=0.760 total time= 2.3min\n",
      "[CV 4/5] END .................C=100, gamma=0.01;, score=0.765 total time= 2.3min\n",
      "[CV 5/5] END .................C=100, gamma=0.01;, score=0.772 total time= 2.2min\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.781 total time= 1.7min\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.809 total time= 1.7min\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.784 total time= 1.7min\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.786 total time= 1.7min\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.788 total time= 1.7min\n",
      "[CV 1/5] END ...................C=1, gamma=0.01;, score=0.786 total time= 1.9min\n",
      "[CV 2/5] END ...................C=1, gamma=0.01;, score=0.812 total time= 2.0min\n",
      "[CV 3/5] END ...................C=1, gamma=0.01;, score=0.785 total time= 1.8min\n",
      "[CV 4/5] END ...................C=1, gamma=0.01;, score=0.783 total time= 1.7min\n",
      "[CV 5/5] END ...................C=1, gamma=0.01;, score=0.808 total time= 1.7min\n",
      "[CV 1/5] END ..................C=1, gamma=0.001;, score=0.744 total time= 1.8min\n",
      "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.760 total time= 1.8min\n",
      "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.745 total time= 1.8min\n",
      "[CV 4/5] END ..................C=1, gamma=0.001;, score=0.752 total time= 1.8min\n",
      "[CV 5/5] END ..................C=1, gamma=0.001;, score=0.752 total time= 1.8min\n",
      "[CV 1/5] END ..............C=1000, gamma=0.0001;, score=0.765 total time= 1.4min\n",
      "[CV 2/5] END ..............C=1000, gamma=0.0001;, score=0.790 total time= 1.6min\n",
      "[CV 3/5] END ..............C=1000, gamma=0.0001;, score=0.770 total time= 1.5min\n",
      "[CV 4/5] END ..............C=1000, gamma=0.0001;, score=0.761 total time= 1.5min\n",
      "[CV 5/5] END ..............C=1000, gamma=0.0001;, score=0.781 total time= 1.5min\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.729 total time= 2.7min\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.724 total time= 2.8min\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.740 total time= 2.8min\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.768 total time= 2.8min\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.761 total time= 2.6min\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.767 total time= 2.2min\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=0.790 total time= 2.4min\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.761 total time= 2.3min\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=0.763 total time= 2.3min\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=0.775 total time= 2.3min\n",
      "[CV 1/5] END ................C=0.1, gamma=0.001;, score=0.661 total time= 2.1min\n",
      "[CV 2/5] END ................C=0.1, gamma=0.001;, score=0.661 total time= 2.3min\n",
      "[CV 3/5] END ................C=0.1, gamma=0.001;, score=0.661 total time= 2.4min\n",
      "[CV 4/5] END ................C=0.1, gamma=0.001;, score=0.661 total time= 2.7min\n",
      "[CV 5/5] END ................C=0.1, gamma=0.001;, score=0.661 total time= 2.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 10:47:23.990472: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 7ms/step\n",
      "76/76 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n",
      "100%|██████████| 9673/9673 [00:06<00:00, 1544.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[10:49:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  30.6s\n",
      "[10:49:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  27.2s\n",
      "[10:50:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  27.2s\n",
      "[10:50:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  25.3s\n",
      "[10:51:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  27.8s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.845 total time= 5.6min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.823 total time= 5.3min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.870 total time= 3.6min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.862 total time= 3.7min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.846 total time= 4.1min\n",
      "[11:13:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  27.6s\n",
      "[11:14:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  27.5s\n",
      "[11:14:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  31.0s\n",
      "[11:15:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  25.9s\n",
      "[11:15:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  24.1s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.844 total time= 3.3min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.827 total time= 2.9min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.870 total time= 3.0min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.861 total time= 3.3min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.849 total time= 3.1min\n",
      "[11:31:39] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  17.2s\n",
      "[11:31:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  17.3s\n",
      "[11:32:13] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  17.4s\n",
      "[11:32:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  17.3s\n",
      "[11:32:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=  17.5s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.843 total time= 4.8min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.825 total time= 4.4min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.874 total time= 4.3min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.862 total time= 4.8min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.847 total time= 4.7min\n",
      "[11:56:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  21.4s\n",
      "[11:56:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  20.2s\n",
      "[11:56:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  19.3s\n",
      "[11:57:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  21.2s\n",
      "[11:57:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  24.9s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.836 total time= 2.4min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.814 total time= 2.5min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.865 total time= 2.8min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.855 total time= 2.9min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.843 total time= 2.8min\n",
      "[12:11:24] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=  26.2s\n",
      "[12:11:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=  26.2s\n",
      "[12:12:16] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=  26.1s\n",
      "[12:12:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=  25.4s\n",
      "[12:13:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.500 total time=  26.6s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.845 total time= 4.1min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.821 total time= 4.2min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.868 total time= 4.1min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.864 total time= 4.3min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.848 total time= 4.2min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.847 total time= 8.0min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.824 total time= 7.2min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.870 total time= 7.6min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.869 total time= 8.1min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.847 total time= 8.0min\n",
      "[13:13:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  33.6s\n",
      "[13:13:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  27.7s\n",
      "[13:14:20] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  28.1s\n",
      "[13:14:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  32.8s\n",
      "[13:15:21] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  25.9s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.840 total time= 4.1min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.824 total time= 3.9min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.872 total time= 3.4min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.864 total time= 3.4min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.846 total time= 3.6min\n",
      "[13:34:17] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  18.6s\n",
      "[13:34:36] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  14.5s\n",
      "[13:34:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  13.9s\n",
      "[13:35:04] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  14.0s\n",
      "[13:35:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=  15.0s\n",
      "[13:35:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  22.5s\n",
      "[13:35:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  22.3s\n",
      "[13:36:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  22.1s\n",
      "[13:36:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  22.4s\n",
      "[13:37:03] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  21.9s\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END ................C=0.1, gamma=0.001;, score=0.659 total time= 2.4min\n",
      "[CV 2/5] END ................C=0.1, gamma=0.001;, score=0.660 total time= 2.4min\n",
      "[CV 3/5] END ................C=0.1, gamma=0.001;, score=0.660 total time= 2.4min\n",
      "[CV 4/5] END ................C=0.1, gamma=0.001;, score=0.660 total time= 2.3min\n",
      "[CV 5/5] END ................C=0.1, gamma=0.001;, score=0.660 total time= 2.3min\n",
      "[CV 1/5] END ...............C=1000, gamma=0.001;, score=0.774 total time= 2.1min\n",
      "[CV 2/5] END ...............C=1000, gamma=0.001;, score=0.748 total time= 2.0min\n",
      "[CV 3/5] END ...............C=1000, gamma=0.001;, score=0.778 total time= 2.0min\n",
      "[CV 4/5] END ...............C=1000, gamma=0.001;, score=0.783 total time= 2.2min\n",
      "[CV 5/5] END ...............C=1000, gamma=0.001;, score=0.759 total time= 2.2min\n",
      "[CV 1/5] END .................C=1, gamma=0.0001;, score=0.659 total time= 2.5min\n",
      "[CV 2/5] END .................C=1, gamma=0.0001;, score=0.660 total time= 2.5min\n",
      "[CV 3/5] END .................C=1, gamma=0.0001;, score=0.660 total time= 2.3min\n",
      "[CV 4/5] END .................C=1, gamma=0.0001;, score=0.660 total time= 2.3min\n",
      "[CV 5/5] END .................C=1, gamma=0.0001;, score=0.660 total time= 2.4min\n",
      "[CV 1/5] END .................C=100, gamma=0.01;, score=0.771 total time= 2.5min\n",
      "[CV 2/5] END .................C=100, gamma=0.01;, score=0.766 total time= 2.5min\n",
      "[CV 3/5] END .................C=100, gamma=0.01;, score=0.786 total time= 2.6min\n",
      "[CV 4/5] END .................C=100, gamma=0.01;, score=0.777 total time= 2.4min\n",
      "[CV 5/5] END .................C=100, gamma=0.01;, score=0.764 total time= 2.6min\n",
      "[CV 1/5] END ....................C=0.1, gamma=1;, score=0.659 total time= 2.9min\n",
      "[CV 2/5] END ....................C=0.1, gamma=1;, score=0.660 total time= 2.6min\n",
      "[CV 3/5] END ....................C=0.1, gamma=1;, score=0.660 total time= 2.7min\n",
      "[CV 4/5] END ....................C=0.1, gamma=1;, score=0.660 total time= 2.7min\n",
      "[CV 5/5] END ....................C=0.1, gamma=1;, score=0.660 total time= 2.7min\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.659 total time= 2.9min\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.660 total time= 2.9min\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.658 total time= 3.1min\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.660 total time= 3.0min\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.660 total time= 3.0min\n",
      "[CV 1/5] END ................C=100, gamma=0.001;, score=0.761 total time= 1.6min\n",
      "[CV 2/5] END ................C=100, gamma=0.001;, score=0.757 total time= 1.5min\n",
      "[CV 3/5] END ................C=100, gamma=0.001;, score=0.785 total time= 1.6min\n",
      "[CV 4/5] END ................C=100, gamma=0.001;, score=0.786 total time= 1.5min\n",
      "[CV 5/5] END ................C=100, gamma=0.001;, score=0.764 total time= 1.5min\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.744 total time= 2.8min\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.748 total time= 2.9min\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.755 total time= 3.0min\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.736 total time= 2.9min\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.742 total time= 2.9min\n",
      "[CV 1/5] END ................C=1000, gamma=0.01;, score=0.770 total time= 2.4min\n",
      "[CV 2/5] END ................C=1000, gamma=0.01;, score=0.763 total time= 2.6min\n",
      "[CV 3/5] END ................C=1000, gamma=0.01;, score=0.785 total time= 2.5min\n",
      "[CV 4/5] END ................C=1000, gamma=0.01;, score=0.778 total time= 2.5min\n",
      "[CV 5/5] END ................C=1000, gamma=0.01;, score=0.767 total time= 2.3min\n",
      "[CV 1/5] END ..................C=100, gamma=0.1;, score=0.744 total time= 2.9min\n",
      "[CV 2/5] END ..................C=100, gamma=0.1;, score=0.748 total time= 2.8min\n",
      "[CV 3/5] END ..................C=100, gamma=0.1;, score=0.755 total time= 2.5min\n",
      "[CV 4/5] END ..................C=100, gamma=0.1;, score=0.736 total time= 2.6min\n",
      "[CV 5/5] END ..................C=100, gamma=0.1;, score=0.742 total time= 2.5min\n",
      "[CV 1/5] END ...................C=1, gamma=0.01;, score=0.776 total time= 1.6min\n",
      "[CV 2/5] END ...................C=1, gamma=0.01;, score=0.775 total time= 1.6min\n",
      "[CV 3/5] END ...................C=1, gamma=0.01;, score=0.809 total time= 1.6min\n",
      "[CV 4/5] END ...................C=1, gamma=0.01;, score=0.812 total time= 1.6min\n",
      "[CV 5/5] END ...................C=1, gamma=0.01;, score=0.784 total time= 1.4min\n",
      "[CV 1/5] END ..................C=1, gamma=0.001;, score=0.739 total time= 1.6min\n",
      "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.735 total time= 1.6min\n",
      "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.766 total time= 1.7min\n",
      "[CV 4/5] END ..................C=1, gamma=0.001;, score=0.762 total time= 1.6min\n",
      "[CV 5/5] END ..................C=1, gamma=0.001;, score=0.744 total time= 1.6min\n",
      "[CV 1/5] END ...................C=10, gamma=0.1;, score=0.744 total time= 2.3min\n",
      "[CV 2/5] END ...................C=10, gamma=0.1;, score=0.748 total time= 2.3min\n",
      "[CV 3/5] END ...................C=10, gamma=0.1;, score=0.755 total time= 2.3min\n",
      "[CV 4/5] END ...................C=10, gamma=0.1;, score=0.736 total time= 2.3min\n",
      "[CV 5/5] END ...................C=10, gamma=0.1;, score=0.742 total time= 2.3min\n",
      "[CV 1/5] END ....................C=100, gamma=1;, score=0.659 total time= 2.4min\n",
      "[CV 2/5] END ....................C=100, gamma=1;, score=0.660 total time= 2.4min\n",
      "[CV 3/5] END ....................C=100, gamma=1;, score=0.658 total time= 2.4min\n",
      "[CV 4/5] END ....................C=100, gamma=1;, score=0.660 total time= 2.4min\n",
      "[CV 5/5] END ....................C=100, gamma=1;, score=0.660 total time= 2.5min\n",
      "[CV 1/5] END .................C=0.1, gamma=0.01;, score=0.698 total time= 1.7min\n",
      "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.705 total time= 1.7min\n",
      "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.721 total time= 1.7min\n",
      "[CV 4/5] END .................C=0.1, gamma=0.01;, score=0.699 total time= 1.8min\n",
      "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.687 total time= 1.7min\n",
      "38/38 [==============================] - 0s 5ms/step\n",
      "76/76 [==============================] - 0s 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n",
      "100%|██████████| 9673/9673 [00:07<00:00, 1344.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.857 total time= 4.6min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.856 total time= 4.4min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.857 total time= 4.6min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.843 total time= 3.5min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.875 total time= 4.2min\n",
      "[17:03:32] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  26.5s\n",
      "[17:03:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  26.7s\n",
      "[17:04:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  23.3s\n",
      "[17:04:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  29.0s\n",
      "[17:05:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  26.8s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.857 total time= 7.3min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.854 total time= 6.5min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.859 total time= 5.3min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.843 total time= 6.2min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.873 total time= 6.7min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.858 total time= 5.7min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.857 total time= 5.7min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.861 total time= 5.4min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.843 total time= 4.7min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.874 total time= 5.5min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.840 total time= 3.2min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.845 total time= 2.8min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.842 total time= 3.0min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.821 total time= 3.2min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.866 total time= 3.0min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.857 total time= 5.0min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.851 total time= 4.4min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.861 total time= 4.4min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.840 total time= 3.6min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.875 total time= 4.6min\n",
      "[18:41:57] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  11.3s\n",
      "[18:42:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=  10.3s\n",
      "[18:42:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=   9.8s\n",
      "[18:42:29] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=   8.8s\n",
      "[18:42:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=3;, score=0.500 total time=   8.2s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.850 total time= 4.6min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.845 total time= 4.6min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.852 total time= 5.5min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.830 total time= 5.3min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.867 total time= 5.2min\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.855 total time= 4.3min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.855 total time= 4.3min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.856 total time= 4.6min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.837 total time= 4.3min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=20, min_child_weight=20, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.871 total time= 4.5min\n",
      "[19:30:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  16.5s\n",
      "[19:30:18] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  17.1s\n",
      "[19:30:35] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  18.4s\n",
      "[19:30:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  15.0s\n",
      "[19:31:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.500 total time=  17.0s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.857 total time= 2.4min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.853 total time= 2.7min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.858 total time= 2.7min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.838 total time= 2.7min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.873 total time= 2.7min\n",
      "[19:44:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  26.0s\n",
      "[19:45:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  25.9s\n",
      "[19:45:26] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  26.5s\n",
      "[19:45:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  26.0s\n",
      "[19:46:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=2;, score=0.500 total time=  23.5s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.857 total time= 5.6min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.855 total time= 5.7min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.858 total time= 5.8min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.839 total time= 5.7min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.871 total time= 5.7min\n",
      "[20:15:10] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  16.5s\n",
      "[20:15:27] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  17.3s\n",
      "[20:15:44] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  17.1s\n",
      "[20:16:01] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  17.8s\n",
      "[20:16:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=  17.7s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.844 total time= 1.5min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.845 total time= 1.6min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.847 total time= 1.5min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.816 total time= 1.5min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=20, n_estimators=300, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.865 total time= 1.6min\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END ................C=10, gamma=0.0001;, score=0.734 total time= 2.1min\n",
      "[CV 2/5] END ................C=10, gamma=0.0001;, score=0.750 total time= 2.1min\n",
      "[CV 3/5] END ................C=10, gamma=0.0001;, score=0.749 total time= 2.0min\n",
      "[CV 4/5] END ................C=10, gamma=0.0001;, score=0.749 total time= 2.0min\n",
      "[CV 5/5] END ................C=10, gamma=0.0001;, score=0.759 total time= 1.8min\n",
      "[CV 1/5] END ......................C=1, gamma=1;, score=0.664 total time= 2.7min\n",
      "[CV 2/5] END ......................C=1, gamma=1;, score=0.664 total time= 2.6min\n",
      "[CV 3/5] END ......................C=1, gamma=1;, score=0.664 total time= 2.6min\n",
      "[CV 4/5] END ......................C=1, gamma=1;, score=0.664 total time= 2.7min\n",
      "[CV 5/5] END ......................C=1, gamma=1;, score=0.664 total time= 2.6min\n",
      "[CV 1/5] END ...............C=100, gamma=0.0001;, score=0.766 total time= 1.5min\n",
      "[CV 2/5] END ...............C=100, gamma=0.0001;, score=0.785 total time= 1.5min\n",
      "[CV 3/5] END ...............C=100, gamma=0.0001;, score=0.788 total time= 1.5min\n",
      "[CV 4/5] END ...............C=100, gamma=0.0001;, score=0.787 total time= 1.5min\n",
      "[CV 5/5] END ...............C=100, gamma=0.0001;, score=0.801 total time= 1.5min\n",
      "[CV 1/5] END .................C=0.1, gamma=0.01;, score=0.683 total time= 1.5min\n",
      "[CV 2/5] END .................C=0.1, gamma=0.01;, score=0.719 total time= 1.5min\n",
      "[CV 3/5] END .................C=0.1, gamma=0.01;, score=0.683 total time= 1.5min\n",
      "[CV 4/5] END .................C=0.1, gamma=0.01;, score=0.707 total time= 1.6min\n",
      "[CV 5/5] END .................C=0.1, gamma=0.01;, score=0.704 total time= 1.5min\n",
      "[CV 1/5] END ..................C=1, gamma=0.001;, score=0.731 total time= 1.5min\n",
      "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.750 total time= 1.6min\n",
      "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.747 total time= 1.5min\n",
      "[CV 4/5] END ..................C=1, gamma=0.001;, score=0.748 total time= 1.5min\n",
      "[CV 5/5] END ..................C=1, gamma=0.001;, score=0.754 total time= 1.6min\n",
      "[CV 1/5] END ....................C=100, gamma=1;, score=0.664 total time= 2.5min\n",
      "[CV 2/5] END ....................C=100, gamma=1;, score=0.664 total time= 2.9min\n",
      "[CV 3/5] END ....................C=100, gamma=1;, score=0.664 total time= 2.8min\n",
      "[CV 4/5] END ....................C=100, gamma=1;, score=0.664 total time= 2.3min\n",
      "[CV 5/5] END ....................C=100, gamma=1;, score=0.664 total time= 2.4min\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.777 total time= 1.4min\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.794 total time= 1.4min\n",
      "[CV 3/5] END ..................C=10, gamma=0.01;, score=0.787 total time= 1.7min\n",
      "[CV 4/5] END ..................C=10, gamma=0.01;, score=0.795 total time= 1.7min\n",
      "[CV 5/5] END ..................C=10, gamma=0.01;, score=0.804 total time= 1.8min\n",
      "[CV 1/5] END .................C=1000, gamma=0.1;, score=0.729 total time= 2.5min\n",
      "[CV 2/5] END .................C=1000, gamma=0.1;, score=0.749 total time= 2.7min\n",
      "[CV 3/5] END .................C=1000, gamma=0.1;, score=0.740 total time= 2.5min\n",
      "[CV 4/5] END .................C=1000, gamma=0.1;, score=0.738 total time= 2.3min\n",
      "[CV 5/5] END .................C=1000, gamma=0.1;, score=0.746 total time= 2.4min\n",
      "[CV 1/5] END .....................C=10, gamma=1;, score=0.664 total time= 2.3min\n",
      "[CV 2/5] END .....................C=10, gamma=1;, score=0.664 total time= 2.3min\n",
      "[CV 3/5] END .....................C=10, gamma=1;, score=0.664 total time= 2.6min\n",
      "[CV 4/5] END .....................C=10, gamma=1;, score=0.664 total time= 2.4min\n",
      "[CV 5/5] END .....................C=10, gamma=1;, score=0.664 total time= 2.5min\n",
      "[CV 1/5] END .................C=10, gamma=0.001;, score=0.767 total time= 1.3min\n",
      "[CV 2/5] END .................C=10, gamma=0.001;, score=0.784 total time= 1.4min\n",
      "[CV 3/5] END .................C=10, gamma=0.001;, score=0.788 total time= 1.3min\n",
      "[CV 4/5] END .................C=10, gamma=0.001;, score=0.791 total time= 1.2min\n",
      "[CV 5/5] END .................C=10, gamma=0.001;, score=0.803 total time= 1.4min\n",
      "[CV 1/5] END ...............C=0.1, gamma=0.0001;, score=0.664 total time= 1.8min\n",
      "[CV 2/5] END ...............C=0.1, gamma=0.0001;, score=0.664 total time= 1.9min\n",
      "[CV 3/5] END ...............C=0.1, gamma=0.0001;, score=0.664 total time= 1.8min\n",
      "[CV 4/5] END ...............C=0.1, gamma=0.0001;, score=0.664 total time= 1.7min\n",
      "[CV 5/5] END ...............C=0.1, gamma=0.0001;, score=0.664 total time= 2.0min\n",
      "[CV 1/5] END .................C=1, gamma=0.0001;, score=0.664 total time= 2.0min\n",
      "[CV 2/5] END .................C=1, gamma=0.0001;, score=0.664 total time= 2.0min\n",
      "[CV 3/5] END .................C=1, gamma=0.0001;, score=0.664 total time= 2.1min\n",
      "[CV 4/5] END .................C=1, gamma=0.0001;, score=0.664 total time= 2.0min\n",
      "[CV 5/5] END .................C=1, gamma=0.0001;, score=0.664 total time= 2.0min\n",
      "[CV 1/5] END ...................C=1000, gamma=1;, score=0.664 total time= 2.6min\n",
      "[CV 2/5] END ...................C=1000, gamma=1;, score=0.664 total time= 2.5min\n",
      "[CV 3/5] END ...................C=1000, gamma=1;, score=0.664 total time= 2.5min\n",
      "[CV 4/5] END ...................C=1000, gamma=1;, score=0.664 total time= 2.5min\n",
      "[CV 5/5] END ...................C=1000, gamma=1;, score=0.664 total time= 2.7min\n",
      "[CV 1/5] END ..............C=1000, gamma=0.0001;, score=0.764 total time= 1.4min\n",
      "[CV 2/5] END ..............C=1000, gamma=0.0001;, score=0.780 total time= 1.5min\n",
      "[CV 3/5] END ..............C=1000, gamma=0.0001;, score=0.780 total time= 1.4min\n",
      "[CV 4/5] END ..............C=1000, gamma=0.0001;, score=0.779 total time= 1.4min\n",
      "[CV 5/5] END ..............C=1000, gamma=0.0001;, score=0.791 total time= 1.5min\n",
      "[CV 1/5] END ....................C=1, gamma=0.1;, score=0.710 total time= 2.6min\n",
      "[CV 2/5] END ....................C=1, gamma=0.1;, score=0.730 total time= 2.5min\n",
      "[CV 3/5] END ....................C=1, gamma=0.1;, score=0.721 total time= 2.8min\n",
      "[CV 4/5] END ....................C=1, gamma=0.1;, score=0.722 total time= 2.6min\n",
      "[CV 5/5] END ....................C=1, gamma=0.1;, score=0.734 total time= 2.5min\n",
      "38/38 [==============================] - 0s 3ms/step\n",
      "76/76 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating training, validation splits...\n",
      "100%|██████████| 9673/9673 [00:04<00:00, 2213.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.836 total time=  36.1s\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.860 total time=  37.4s\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.853 total time=  32.3s\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.868 total time=  34.8s\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.857 total time=  35.7s\n",
      "[23:08:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   2.2s\n",
      "[23:08:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   2.6s\n",
      "[23:08:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   2.7s\n",
      "[23:08:48] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   2.1s\n",
      "[23:08:50] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=25, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   2.9s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.835 total time=  45.9s\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.856 total time=  46.8s\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.854 total time=  39.7s\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.867 total time=  42.0s\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=25, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.858 total time=  42.6s\n",
      "[23:12:30] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   4.1s\n",
      "[23:12:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   3.7s\n",
      "[23:12:38] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   3.9s\n",
      "[23:12:42] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   3.8s\n",
      "[23:12:45] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   3.5s\n",
      "[23:12:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=   3.4s\n",
      "[23:12:52] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=   2.9s\n",
      "[23:12:55] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=   3.1s\n",
      "[23:12:58] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=   3.4s\n",
      "[23:13:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.5, reg_lambda=5;, score=0.500 total time=   3.2s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.838 total time=  47.8s\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.858 total time=  44.8s\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.855 total time=  46.7s\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.870 total time=  47.9s\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=1, learning_rate=0.1, max_depth=15, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=1, reg_lambda=5;, score=0.863 total time=  47.1s\n",
      "[23:16:59] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   2.8s\n",
      "[23:17:02] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   3.1s\n",
      "[23:17:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   2.7s\n",
      "[23:17:08] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   2.9s\n",
      "[23:17:11] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=15, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   3.4s\n",
      "[23:17:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=   4.2s\n",
      "[23:17:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=   4.8s\n",
      "[23:17:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=   4.9s\n",
      "[23:17:28] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=   4.6s\n",
      "[23:17:33] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.8, gamma=3, learning_rate=0.1, max_depth=15, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.500 total time=   4.2s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.829 total time=  42.8s\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.851 total time=  40.8s\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.848 total time=  41.8s\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.864 total time=  41.2s\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.9, gamma=3, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=500, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.857 total time=  41.6s\n",
      "[23:21:05] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   4.1s\n",
      "[23:21:09] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   4.5s\n",
      "[23:21:14] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   4.9s\n",
      "[23:21:19] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   4.5s\n",
      "[23:21:23] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=1, learning_rate=0.1, max_depth=20, min_child_weight=10, n_estimators=600, objective=binary:logistic, reg_alpha=0.5, reg_lambda=3;, score=0.500 total time=   4.5s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.834 total time=  22.9s\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.854 total time=  23.2s\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.849 total time=  22.9s\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.866 total time=  21.4s\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=7, min_child_weight=15, n_estimators=300, objective=binary:logistic, reg_alpha=0.2, reg_lambda=2;, score=0.855 total time=  23.0s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.843 total time= 1.0min\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.860 total time= 1.0min\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.859 total time= 1.0min\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.868 total time= 1.0min\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=1, learning_rate=0.1, max_depth=10, min_child_weight=20, n_estimators=600, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.864 total time= 1.0min\n",
      "[23:28:31] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   3.2s\n",
      "[23:28:34] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   3.0s\n",
      "[23:28:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   2.9s\n",
      "[23:28:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   3.2s\n",
      "[23:28:43] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=1, gamma=2, learning_rate=0.1, max_depth=15, min_child_weight=10, n_estimators=400, objective=binary:logistic, reg_alpha=0.2, reg_lambda=5;, score=0.500 total time=   3.0s\n",
      "[23:28:46] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 1/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=   3.6s\n",
      "[23:28:49] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 2/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=   3.4s\n",
      "[23:28:53] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 3/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=   3.3s\n",
      "[23:28:56] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 4/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=   4.0s\n",
      "[23:29:00] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-cpython-38/xgboost/src/learner.cc:767: \n",
      "Parameters: { \"colsample_bytree\", \"gamma\", \"max_depth\", \"min_child_weight\" } are not used.\n",
      "\n",
      "[CV 5/5] END booster=gblinear, colsample_bytree=0.9, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=500, objective=binary:logistic, reg_alpha=1, reg_lambda=3;, score=0.500 total time=   3.9s\n",
      "[CV 1/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.841 total time=  37.5s\n",
      "[CV 2/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.856 total time=  37.6s\n",
      "[CV 3/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.855 total time=  37.1s\n",
      "[CV 4/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.869 total time=  37.3s\n",
      "[CV 5/5] END booster=gbtree, colsample_bytree=0.8, gamma=2, learning_rate=0.1, max_depth=10, min_child_weight=25, n_estimators=400, objective=binary:logistic, reg_alpha=1, reg_lambda=2;, score=0.859 total time=  37.0s\n",
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5] END ..................C=1, gamma=0.001;, score=0.751 total time= 1.8min\n",
      "[CV 2/5] END ..................C=1, gamma=0.001;, score=0.757 total time= 1.9min\n",
      "[CV 3/5] END ..................C=1, gamma=0.001;, score=0.766 total time= 1.9min\n",
      "[CV 4/5] END ..................C=1, gamma=0.001;, score=0.760 total time= 2.0min\n",
      "[CV 5/5] END ..................C=1, gamma=0.001;, score=0.748 total time= 1.9min\n",
      "[CV 1/5] END ..................C=10, gamma=0.01;, score=0.789 total time= 1.7min\n",
      "[CV 2/5] END ..................C=10, gamma=0.01;, score=0.781 total time= 1.7min\n"
     ]
    }
   ],
   "source": [
    "group = admet_group(path = 'data/')\n",
    "\n",
    "pred_valid_list_xgb = []\n",
    "pred_valid_list_rf = []\n",
    "pred_valid_list_svm = []\n",
    "pred_valid_list_adb = []\n",
    "pred_valid_list_cnn = []\n",
    "        \n",
    "pred_test_list_xgb = []\n",
    "pred_test_list_rf = []\n",
    "pred_test_list_svm = []\n",
    "pred_test_list_adb = []\n",
    "pred_test_list_cnn = []\n",
    "\n",
    "best_params_list_xgb = []\n",
    "best_params_list_svm = []\n",
    "\n",
    "for seed in [1, 2, 3, 4, 5]:\n",
    "    pred_valid_xgb = {}\n",
    "    pred_valid_rf = {}\n",
    "    pred_valid_svm = {}\n",
    "    pred_valid_adb = {}\n",
    "    pred_valid_cnn = {}\n",
    "\n",
    "    pred_test_xgb = {}\n",
    "    pred_test_rf = {}\n",
    "    pred_test_svm = {}\n",
    "    pred_test_adb = {}\n",
    "    pred_test_cnn = {}\n",
    "\n",
    "    benchmark = group.get('CYP2C9_Veith')\n",
    "    name = benchmark['name']\n",
    "    train_val, test = benchmark['train_val'], benchmark['test']\n",
    "    train, valid = group.get_train_valid_split(benchmark = name, split_type = 'default', seed = seed)\n",
    "\n",
    "    PandasTools.AddMoleculeColumnToFrame(train, smilesCol='Drug')\n",
    "    radius=2\n",
    "    nBits=1024\n",
    "    ECFP6 = [AllChem.GetMorganFingerprintAsBitVect(x,radius=radius, nBits=nBits) for x in train['ROMol']]\n",
    "    ecfp6_name = [f'Bit_{i}' for i in range(nBits)]\n",
    "    ecfp6_bits = [list(l) for l in ECFP6]\n",
    "    Y = train['Y']\n",
    "    train = pd.DataFrame(ecfp6_bits, index = train.Drug, columns=ecfp6_name).reset_index(drop = False)\n",
    "    train['Y'] = Y\n",
    "\n",
    "    PandasTools.AddMoleculeColumnToFrame(valid, smilesCol='Drug')\n",
    "    radius=2\n",
    "    nBits=1024\n",
    "    ECFP6 = [AllChem.GetMorganFingerprintAsBitVect(x,radius=radius, nBits=nBits) for x in valid['ROMol']]\n",
    "    ecfp6_name = [f'Bit_{i}' for i in range(nBits)]\n",
    "    ecfp6_bits = [list(l) for l in ECFP6]\n",
    "    Y = valid['Y']\n",
    "    valid = pd.DataFrame(ecfp6_bits, index = valid.Drug, columns=ecfp6_name).reset_index(drop = False)\n",
    "    valid['Y'] = Y\n",
    "\n",
    "    PandasTools.AddMoleculeColumnToFrame(benchmark['test'], smilesCol='Drug')\n",
    "    radius=2\n",
    "    nBits=1024\n",
    "    ECFP6 = [AllChem.GetMorganFingerprintAsBitVect(x,radius=radius, nBits=nBits) for x in benchmark['test']['ROMol']]\n",
    "    ecfp6_name = [f'Bit_{i}' for i in range(nBits)]\n",
    "    ecfp6_bits = [list(l) for l in ECFP6]\n",
    "    Y = benchmark['test']['Y']\n",
    "    benchmark['test'] = pd.DataFrame(ecfp6_bits, index = benchmark['test'].Drug, columns=ecfp6_name).reset_index(drop = False)\n",
    "    benchmark['test']['Y'] = Y\n",
    "\n",
    "    train_X = train.drop(columns = [\"Drug\",\"Y\"])\n",
    "    train_y = train.Y\n",
    "    valid_X = valid.drop(columns = [\"Drug\",\"Y\"])\n",
    "    globals()['valid_y_%s'%seed] = valid.Y\n",
    "    test_X = benchmark['test'].drop(columns = [\"Drug\",\"Y\"])\n",
    "    test_y = benchmark['test'].Y\n",
    "\n",
    "\n",
    "    #XGBoost + Morgan\n",
    "    xgb_parameters = {'objective':['binary:logistic'],\n",
    "    'booster':['gbtree','gblinear'],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [7,10,15,20],\n",
    "    'min_child_weight': [10,15,20,25],\n",
    "    'colsample_bytree': [0.8, 0.9, 1],\n",
    "    'n_estimators': [300,400,500,600],\n",
    "    \"reg_alpha\"   : [0.5,0.2,1],\n",
    "    \"reg_lambda\"  : [2,3,5],\n",
    "    \"gamma\"       : [1,2,3]}\n",
    "\n",
    "    xgb_model = XGBClassifier()\n",
    "    grid_obj_xgb = RandomizedSearchCV(xgb_model, xgb_parameters, cv=5, n_iter=15, scoring = 'roc_auc', verbose=5, n_jobs=1)\n",
    "    grid_obj_xgb.fit(train_X, train_y, verbose = 1)\n",
    "    y_pred_valid_xgb = grid_obj_xgb.predict_proba(valid_X)\n",
    "    y_pred_test_xgb = grid_obj_xgb.predict_proba(test_X)\n",
    "    pred_valid_xgb[name] = pred_prob_to_score(y_pred_valid_xgb)\n",
    "    pred_valid_list_xgb.append(pred_valid_xgb)\n",
    "    pred_test_xgb[name] = pred_prob_to_score(y_pred_test_xgb)\n",
    "    pred_test_list_xgb.append(pred_test_xgb)\n",
    "    bp_xgb = grid_obj_xgb.best_params_\n",
    "    best_params_list_xgb.append(bp_xgb)\n",
    "\n",
    "    #Random Forest + Morgan\n",
    "    rf_model = RandomForestClassifier()\n",
    "    rf_model.fit(train_X, train_y)\n",
    "    y_pred_valid_rf = rf_model.predict_proba(valid_X)\n",
    "    y_pred_test_rf = rf_model.predict_proba(test_X)\n",
    "    pred_valid_rf[name] = pred_prob_to_score(y_pred_valid_rf)\n",
    "    pred_valid_list_rf.append(pred_valid_rf)\n",
    "    pred_test_rf[name] = pred_prob_to_score(y_pred_test_rf)\n",
    "    pred_test_list_rf.append(pred_test_rf)\n",
    "\n",
    "    #SVM + Morgan\n",
    "    svm_parameters = {\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "    }\n",
    "    svm_model = SVC(kernel=\"rbf\", probability=True)\n",
    "    grid_obj_svm = RandomizedSearchCV(svm_model, svm_parameters, cv=5, n_iter=15, verbose=5, n_jobs=1)\n",
    "    grid_obj_svm.fit(train_X, train_y)\n",
    "    y_pred_valid_svm = grid_obj_svm.predict_proba(valid_X)\n",
    "    y_pred_test_svm = grid_obj_svm.predict_proba(test_X)\n",
    "    pred_valid_svm[name] = pred_prob_to_score(y_pred_valid_svm)\n",
    "    pred_valid_list_svm.append(pred_valid_svm)\n",
    "    pred_test_svm[name] = pred_prob_to_score(y_pred_test_svm)\n",
    "    pred_test_list_svm.append(pred_test_svm)\n",
    "    bp_svm = grid_obj_svm.best_params_\n",
    "    best_params_list_svm.append(bp_svm)\n",
    "\n",
    "    # AdaBoost + Morgan\n",
    "    DTC = DecisionTreeClassifier(max_depth=4)\n",
    "    adb_model = AdaBoostClassifier(n_estimators=300, base_estimator=DTC, learning_rate=1)\n",
    "    adb_model.fit(train_X, train_y)\n",
    "    y_pred_valid_adb = adb_model.predict_proba(valid_X)\n",
    "    y_pred_test_adb = adb_model.predict_proba(test_X)\n",
    "    pred_valid_adb[name] = pred_prob_to_score(y_pred_valid_adb)\n",
    "    pred_valid_list_adb.append(pred_valid_adb)\n",
    "    pred_test_adb[name] = pred_prob_to_score(y_pred_test_adb)\n",
    "    pred_test_list_adb.append(pred_test_adb)\n",
    "\n",
    "    #CNN + Morgan\n",
    "    train_X_cnn = train_X.to_numpy()\n",
    "    valid_X_cnn = valid_X.to_numpy()\n",
    "    test_X_cnn = test_X.to_numpy()\n",
    "    train_X_cnn = train_X_cnn.reshape(train_X_cnn.shape[0], train_X_cnn.shape[1], 1)\n",
    "    valid_X_cnn = valid_X_cnn.reshape(valid_X_cnn.shape[0], valid_X_cnn.shape[1], 1)\n",
    "    test_X_cnn = test_X_cnn.reshape(test_X_cnn.shape[0], test_X_cnn.shape[1], 1)\n",
    "    train_X = train_X.astype('float32')\n",
    "    valid_X = valid_X.astype('float32')\n",
    "    test_X = test_X.astype('float32')\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv1D(32, 2, padding=\"valid\", activation=\"relu\", input_shape=(1024,1)))\n",
    "    cnn_model.add(Flatten())\n",
    "    cnn_model.add(Dense(64, activation=\"relu\"))\n",
    "    cnn_model.add(Dense(1,activation='sigmoid'))\n",
    "    cnn_model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=\"adam\", metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.FalseNegatives()])\n",
    "    cnn_model.fit(train_X_cnn, train_y, batch_size=12, epochs=10, verbose=0)\n",
    "    y_pred_valid_cnn = cnn_model.predict(valid_X_cnn)\n",
    "    y_pred_test_cnn = cnn_model.predict(test_X_cnn)\n",
    "    y_pred_valid_cnn_copy = []\n",
    "    for i in range(len(y_pred_valid_cnn)):\n",
    "        y_pred_valid_cnn_copy.append(y_pred_valid_cnn[i][0])\n",
    "    y_pred_test_cnn_copy = []\n",
    "    for i in range(len(y_pred_test_cnn)):\n",
    "        y_pred_test_cnn_copy.append(y_pred_test_cnn[i][0])\n",
    "    pred_valid_cnn[name] = np.array(y_pred_valid_cnn_copy)\n",
    "    pred_valid_list_cnn.append(pred_valid_cnn)\n",
    "    pred_test_cnn[name] = np.array(y_pred_test_cnn_copy)\n",
    "    pred_test_list_cnn.append(pred_test_cnn)\n",
    "\n",
    "xgb_perform = group.evaluate_many(pred_test_list_xgb)\n",
    "rf_perform = group.evaluate_many(pred_test_list_rf)\n",
    "svm_perform = group.evaluate_many(pred_test_list_svm)\n",
    "adb_perform = group.evaluate_many(pred_test_list_adb)\n",
    "cnn_perform = group.evaluate_many(pred_test_list_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"xgb_perform:\", xgb_perform, \"\\n rf_perform:\", rf_perform, \"\\n svm_perform:\", svm_perform, \"\\n adb_perform:\", adb_perform, \"\\n cnn_perform:\", cnn_perform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = benchmark['test'].Y\n",
    "y_test = np.array(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_object(array): # convert scores into ranks\n",
    "    arg_a = np.argsort(array)\n",
    "    b = np.flip(np.arange(len(arg_a)))\n",
    "    a = np.zeros_like(arg_a)\n",
    "    for i in range(len(arg_a)):\n",
    "        a[arg_a[i]] = b[i]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_rank(array):\n",
    "  res = np.argsort(np.flip(np.argsort(array)))+1\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array): # define function for normalization of scores\n",
    "    maximum = np.max(array)\n",
    "    minimum = np.min(array)\n",
    "    norm_list = []\n",
    "    for i in range(len(array)):\n",
    "        norm_list.append((array[i]-minimum)/(maximum-minimum))\n",
    "    return np.array(norm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_valid_xgb = []\n",
    "predictions_valid_rf = []\n",
    "predictions_valid_svm = []\n",
    "predictions_valid_adb = []\n",
    "predictions_valid_cnn = []\n",
    "\n",
    "predictions_test_xgb = []\n",
    "predictions_test_rf = []\n",
    "predictions_test_svm = []\n",
    "predictions_test_adb = []\n",
    "predictions_test_cnn = []\n",
    "\n",
    "scoreSys = ['xgb', 'rf', 'svm', 'adb', 'cnn']\n",
    "\n",
    "for sys in scoreSys:\n",
    "  for seed in range(len(globals()['pred_valid_list_%s' % sys])):\n",
    "    globals()['predictions_valid_%s' % sys].append(list(globals()['pred_valid_list_%s' % sys][seed].values())[0])\n",
    "\n",
    "for sys in scoreSys:\n",
    "  for seed in range(len(globals()['pred_test_list_%s' % sys])):\n",
    "    globals()['predictions_test_%s' % sys].append(list(globals()['pred_test_list_%s' % sys][seed].values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSC graphs\n",
    "colors = ['r--', 'm--', 'b--', 'g--', 'y--']\n",
    "\n",
    "for seed in range(len(globals()['predictions_valid_%s' % sys])):\n",
    "  ranks = np.flip(np.arange(len(predictions_valid_xgb[seed])))\n",
    "  fig, ax = plt.subplots()\n",
    "  for z in range(len(scoreSys)):\n",
    "    globals()['line%s' % (z+1)] = plt.plot(ranks, np.sort(normalize(globals()['predictions_valid_%s' % scoreSys[z]][seed])), colors[z], label = scoreSys[z])\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.title('RSC Graphs of Base Models - Seed %s' % str(seed+1))\n",
    "    plt.xlabel('Rank Value')\n",
    "    plt.ylabel('Normalized Score')\n",
    "  plt.show()\n",
    "  image_name = benchmark['name'] + '_morgan_rsc_seed_%s'% str(seed+1) + '.png'\n",
    "  image_format = 'png'\n",
    "  fig.savefig(image_name, format=image_format, dpi=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_score = [[] for _ in range(5)]\n",
    "for sys in scoreSys:\n",
    "  for seed in range(len(ds_score)):\n",
    "    loc = scoreSys.index(sys)\n",
    "    scoreSys.remove(sys)\n",
    "    ds = 0\n",
    "    for i in range(len(scoreSys)):\n",
    "      ds += np.sum(np.square(normalize(np.sort(globals()['predictions_valid_%s' % sys][seed]))-normalize(np.sort(globals()['predictions_valid_%s' % scoreSys[i]][seed]))))\n",
    "    ds = ds/len(scoreSys)\n",
    "    scoreSys.insert(loc, sys)\n",
    "    ds_score[seed].append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rank = np.reciprocal(ds_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdc import Evaluator\n",
    "def get_auprc(y_pred_proba, y_true):\n",
    "  evaluator = Evaluator(name = 'PR-AUC')\n",
    "  res = evaluator(y_true, y_pred_proba)\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score = [[] for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sys in scoreSys:\n",
    "  for seed in range(len(ps_score)):\n",
    "    ps = get_auprc(globals()['predictions_valid_%s' % sys][seed], globals()['valid_y_%s'%str(seed+1)])\n",
    "    ps_score[seed].append(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(s):\n",
    "    x = len(s)\n",
    "    ls = []\n",
    "    for i in range(1 << x):\n",
    "        ls.append([s[j] for j in range(x) if (i & (1 << j))])\n",
    "    return ls[1:]\n",
    "\n",
    "models = powerset(scoreSys)\n",
    "\n",
    "def myFunc(e):\n",
    "  return len(e)\n",
    "\n",
    "models.sort(key=myFunc)\n",
    "\n",
    "models_list = []\n",
    "for i in range(len(models)):\n",
    "  if len(models[i]) == 1:\n",
    "    models_list.append(models[i][0])\n",
    "  elif len(models[i]) == 2:\n",
    "    models_list.append(models[i][0]+'&'+models[i][1])\n",
    "  elif len(models[i]) == 3:\n",
    "    models_list.append(models[i][0]+'&'+models[i][1]+'&'+models[i][2])\n",
    "  elif len(models[i]) == 4:\n",
    "    models_list.append(models[i][0]+'&'+models[i][1]+'&'+models[i][2]+'&'+models[i][3])\n",
    "  elif len(models[i]) == 5:\n",
    "    models_list.append(models[i][0]+'&'+models[i][1]+'&'+models[i][2]+'&'+models[i][3]+'&'+models[i][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform average score combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_combine_seed1 = pd.DataFrame({'xgb':predictions_test_xgb[0], 'rf':predictions_test_rf[0], 'svm':predictions_test_svm[0], 'adb':predictions_test_adb[0], 'cnn':predictions_test_cnn[0]})\n",
    "avg_score_combine_seed2 = pd.DataFrame({'xgb':predictions_test_xgb[1], 'rf':predictions_test_rf[1], 'svm':predictions_test_svm[1], 'adb':predictions_test_adb[1], 'cnn':predictions_test_cnn[1]})\n",
    "avg_score_combine_seed3 = pd.DataFrame({'xgb':predictions_test_xgb[2], 'rf':predictions_test_rf[2], 'svm':predictions_test_svm[2], 'adb':predictions_test_adb[2], 'cnn':predictions_test_cnn[2]})\n",
    "avg_score_combine_seed4 = pd.DataFrame({'xgb':predictions_test_xgb[3], 'rf':predictions_test_rf[3], 'svm':predictions_test_svm[3], 'adb':predictions_test_adb[3], 'cnn':predictions_test_cnn[3]})\n",
    "avg_score_combine_seed5 = pd.DataFrame({'xgb':predictions_test_xgb[4], 'rf':predictions_test_rf[4], 'svm':predictions_test_svm[4], 'adb':predictions_test_adb[4], 'cnn':predictions_test_cnn[4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_score_combine(models_list, single_score):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      single_score[j] = (single_score[j.split('&')[0]]+single_score[j.split('&')[1]]) / 2\n",
    "    elif len(j.split('&')) == 3:\n",
    "      single_score[j] = (single_score[j.split('&')[0]]+single_score[j.split('&')[1]]+single_score[j.split('&')[2]]) / 3\n",
    "    elif len(j.split('&')) == 4:\n",
    "      single_score[j] = (single_score[j.split('&')[0]]+single_score[j.split('&')[1]]+single_score[j.split('&')[2]]+single_score[j.split('&')[3]]) / 4\n",
    "    elif len(j.split('&')) == 5:\n",
    "      single_score[j] = (single_score[j.split('&')[0]]+single_score[j.split('&')[1]]+single_score[j.split('&')[2]]+single_score[j.split('&')[3]]+single_score[j.split('&')[4]]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_score_combine(models_list, avg_score_combine_seed1)\n",
    "avg_score_combine(models_list, avg_score_combine_seed2)\n",
    "avg_score_combine(models_list, avg_score_combine_seed3)\n",
    "avg_score_combine(models_list, avg_score_combine_seed4)\n",
    "avg_score_combine(models_list, avg_score_combine_seed5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform average rank combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_to_rank(array):\n",
    "  res = np.argsort(np.flip(np.argsort(array)))+1\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rank_combine_seed1 = pd.DataFrame({'xgb':score_to_rank(predictions_test_xgb[0]), 'rf':score_to_rank(predictions_test_rf[0]), 'svm':score_to_rank(predictions_test_svm[0]), 'adb':score_to_rank(predictions_test_adb[0]), 'cnn':score_to_rank(predictions_test_cnn[0])})\n",
    "avg_rank_combine_seed2 = pd.DataFrame({'xgb':score_to_rank(predictions_test_xgb[1]), 'rf':score_to_rank(predictions_test_rf[1]), 'svm':score_to_rank(predictions_test_svm[1]), 'adb':score_to_rank(predictions_test_adb[1]), 'cnn':score_to_rank(predictions_test_cnn[1])})\n",
    "avg_rank_combine_seed3 = pd.DataFrame({'xgb':score_to_rank(predictions_test_xgb[2]), 'rf':score_to_rank(predictions_test_rf[2]), 'svm':score_to_rank(predictions_test_svm[2]), 'adb':score_to_rank(predictions_test_adb[2]), 'cnn':score_to_rank(predictions_test_cnn[2])})\n",
    "avg_rank_combine_seed4 = pd.DataFrame({'xgb':score_to_rank(predictions_test_xgb[3]), 'rf':score_to_rank(predictions_test_rf[3]), 'svm':score_to_rank(predictions_test_svm[3]), 'adb':score_to_rank(predictions_test_adb[3]), 'cnn':score_to_rank(predictions_test_cnn[3])})\n",
    "avg_rank_combine_seed5 = pd.DataFrame({'xgb':score_to_rank(predictions_test_xgb[4]), 'rf':score_to_rank(predictions_test_rf[4]), 'svm':score_to_rank(predictions_test_svm[4]), 'adb':score_to_rank(predictions_test_adb[4]), 'cnn':score_to_rank(predictions_test_cnn[4])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_rank_combine(models_list, single_rank):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      single_rank[j+'_r'] = (single_rank[j.split('&')[0]]+single_rank[j.split('&')[1]]) / 2\n",
    "    elif len(j.split('&')) == 3:\n",
    "      single_rank[j+'_r'] = (single_rank[j.split('&')[0]]+single_rank[j.split('&')[1]]+single_rank[j.split('&')[2]]) / 3\n",
    "    elif len(j.split('&')) == 4:\n",
    "      single_rank[j+'_r'] = (single_rank[j.split('&')[0]]+single_rank[j.split('&')[1]]+single_rank[j.split('&')[2]]+single_rank[j.split('&')[3]]) / 4\n",
    "    elif len(j.split('&')) == 5:\n",
    "      single_rank[j+'_r'] = (single_rank[j.split('&')[0]]+single_rank[j.split('&')[1]]+single_rank[j.split('&')[2]]+single_rank[j.split('&')[3]]+single_rank[j.split('&')[4]]) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rank_combine(models_list, avg_rank_combine_seed1)\n",
    "avg_rank_combine(models_list, avg_rank_combine_seed2)\n",
    "avg_rank_combine(models_list, avg_rank_combine_seed3)\n",
    "avg_rank_combine(models_list, avg_rank_combine_seed4)\n",
    "avg_rank_combine(models_list, avg_rank_combine_seed5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform weighted score combination by diversity strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_score_combine_seed1 = pd.DataFrame()\n",
    "ds_score_combine_seed2 = pd.DataFrame()\n",
    "ds_score_combine_seed3 = pd.DataFrame()\n",
    "ds_score_combine_seed4 = pd.DataFrame()\n",
    "ds_score_combine_seed5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_score_combine(models_list, single_score, ds_score_combine, ds_score):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      ds_score_combine[j+'_ds'] = (single_score[j.split('&')[0]]*ds_score[scoreSys.index(j.split('&')[0])]+single_score[j.split('&')[1]]*ds_score[scoreSys.index(j.split('&')[1])])/(ds_score[scoreSys.index(j.split('&')[0])] + ds_score[scoreSys.index(j.split('&')[1])])\n",
    "    elif len(j.split('&')) == 3:\n",
    "      ds_score_combine[j+'_ds'] = (single_score[j.split('&')[0]]*ds_score[scoreSys.index(j.split('&')[0])]+single_score[j.split('&')[1]]*ds_score[scoreSys.index(j.split('&')[1])]+single_score[j.split('&')[2]]*ds_score[scoreSys.index(j.split('&')[2])])/(ds_score[scoreSys.index(j.split('&')[0])] + ds_score[scoreSys.index(j.split('&')[1])] + ds_score[scoreSys.index(j.split('&')[2])])\n",
    "    elif len(j.split('&')) == 4:\n",
    "      ds_score_combine[j+'_ds'] = (single_score[j.split('&')[0]]*ds_score[scoreSys.index(j.split('&')[0])]+single_score[j.split('&')[1]]*ds_score[scoreSys.index(j.split('&')[1])]+single_score[j.split('&')[2]]*ds_score[scoreSys.index(j.split('&')[2])]+single_score[j.split('&')[3]]*ds_score[scoreSys.index(j.split('&')[3])])/(ds_score[scoreSys.index(j.split('&')[0])] + ds_score[scoreSys.index(j.split('&')[1])] + ds_score[scoreSys.index(j.split('&')[2])] + ds_score[scoreSys.index(j.split('&')[3])])\n",
    "    elif len(j.split('&')) == 5:\n",
    "      ds_score_combine[j+'_ds'] = (single_score[j.split('&')[0]]*ds_score[scoreSys.index(j.split('&')[0])]+single_score[j.split('&')[1]]*ds_score[scoreSys.index(j.split('&')[1])]+single_score[j.split('&')[2]]*ds_score[scoreSys.index(j.split('&')[2])]+single_score[j.split('&')[3]]*ds_score[scoreSys.index(j.split('&')[3])]+single_score[j.split('&')[4]]*ds_score[scoreSys.index(j.split('&')[4])])/(ds_score[scoreSys.index(j.split('&')[0])] + ds_score[scoreSys.index(j.split('&')[1])] + ds_score[scoreSys.index(j.split('&')[2])] + ds_score[scoreSys.index(j.split('&')[3])] + ds_score[scoreSys.index(j.split('&')[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_score_combine(models_list, avg_score_combine_seed1, ds_score_combine_seed1, ds_score[0])\n",
    "ds_score_combine(models_list, avg_score_combine_seed2, ds_score_combine_seed2, ds_score[1])\n",
    "ds_score_combine(models_list, avg_score_combine_seed3, ds_score_combine_seed3, ds_score[2])\n",
    "ds_score_combine(models_list, avg_score_combine_seed4, ds_score_combine_seed4, ds_score[3])\n",
    "ds_score_combine(models_list, avg_score_combine_seed5, ds_score_combine_seed5, ds_score[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform weighted rank combination by diversity strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rank_combine_seed1 = pd.DataFrame()\n",
    "ds_rank_combine_seed2 = pd.DataFrame()\n",
    "ds_rank_combine_seed3 = pd.DataFrame()\n",
    "ds_rank_combine_seed4 = pd.DataFrame()\n",
    "ds_rank_combine_seed5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_rank_combine(models_list, single_rank, ds_rank_combine, ds_rank):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      ds_rank_combine[j+'_ds_r'] = (single_rank[j.split('&')[0]]*ds_rank[scoreSys.index(j.split('&')[0])]+single_rank[j.split('&')[1]]*ds_rank[scoreSys.index(j.split('&')[1])])/(ds_rank[scoreSys.index(j.split('&')[0])] + ds_rank[scoreSys.index(j.split('&')[1])])\n",
    "    elif len(j.split('&')) == 3:\n",
    "      ds_rank_combine[j+'_ds_r'] = (single_rank[j.split('&')[0]]*ds_rank[scoreSys.index(j.split('&')[0])]+single_rank[j.split('&')[1]]*ds_rank[scoreSys.index(j.split('&')[1])]+single_rank[j.split('&')[2]]*ds_rank[scoreSys.index(j.split('&')[2])])/(ds_rank[scoreSys.index(j.split('&')[0])] + ds_rank[scoreSys.index(j.split('&')[1])] + ds_rank[scoreSys.index(j.split('&')[2])])\n",
    "    elif len(j.split('&')) == 4:\n",
    "      ds_rank_combine[j+'_ds_r'] = (single_rank[j.split('&')[0]]*ds_rank[scoreSys.index(j.split('&')[0])]+single_rank[j.split('&')[1]]*ds_rank[scoreSys.index(j.split('&')[1])]+single_rank[j.split('&')[2]]*ds_rank[scoreSys.index(j.split('&')[2])]+single_rank[j.split('&')[3]]*ds_rank[scoreSys.index(j.split('&')[3])])/(ds_rank[scoreSys.index(j.split('&')[0])] + ds_rank[scoreSys.index(j.split('&')[1])] + ds_rank[scoreSys.index(j.split('&')[2])] + ds_rank[scoreSys.index(j.split('&')[3])])\n",
    "    elif len(j.split('&')) == 5:\n",
    "      ds_rank_combine[j+'_ds_r'] = (single_rank[j.split('&')[0]]*ds_rank[scoreSys.index(j.split('&')[0])]+single_rank[j.split('&')[1]]*ds_rank[scoreSys.index(j.split('&')[1])]+single_rank[j.split('&')[2]]*ds_rank[scoreSys.index(j.split('&')[2])]+single_rank[j.split('&')[3]]*ds_rank[scoreSys.index(j.split('&')[3])]+single_rank[j.split('&')[4]]*ds_rank[scoreSys.index(j.split('&')[4])])/(ds_rank[scoreSys.index(j.split('&')[0])] + ds_rank[scoreSys.index(j.split('&')[1])] + ds_rank[scoreSys.index(j.split('&')[2])] + ds_rank[scoreSys.index(j.split('&')[3])] + ds_rank[scoreSys.index(j.split('&')[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_rank_combine(models_list, avg_rank_combine_seed1, ds_rank_combine_seed1, ds_rank[0])\n",
    "ds_rank_combine(models_list, avg_rank_combine_seed2, ds_rank_combine_seed2, ds_rank[1])\n",
    "ds_rank_combine(models_list, avg_rank_combine_seed3, ds_rank_combine_seed3, ds_rank[2])\n",
    "ds_rank_combine(models_list, avg_rank_combine_seed4, ds_rank_combine_seed4, ds_rank[3])\n",
    "ds_rank_combine(models_list, avg_rank_combine_seed5, ds_rank_combine_seed5, ds_rank[4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform weighted score combination by performance strength (AUPRC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score_combine_seed1 = pd.DataFrame()\n",
    "ps_score_combine_seed2 = pd.DataFrame()\n",
    "ps_score_combine_seed3 = pd.DataFrame()\n",
    "ps_score_combine_seed4 = pd.DataFrame()\n",
    "ps_score_combine_seed5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps_score_combine(models_list, single_score, ps_score_combine, ps_score):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      ps_score_combine[j+'_ps'] = (single_score[j.split('&')[0]]*(ps_score[scoreSys.index(j.split('&')[0])])+single_score[j.split('&')[1]]*(ps_score[scoreSys.index(j.split('&')[1])]))/(ps_score[scoreSys.index(j.split('&')[0])] + ps_score[scoreSys.index(j.split('&')[1])])\n",
    "    elif len(j.split('&')) == 3:\n",
    "      ps_score_combine[j+'_ps'] = (single_score[j.split('&')[0]]*(ps_score[scoreSys.index(j.split('&')[0])])+single_score[j.split('&')[1]]*(ps_score[scoreSys.index(j.split('&')[1])])+single_score[j.split('&')[2]]*(ps_score[scoreSys.index(j.split('&')[2])]))/(ps_score[scoreSys.index(j.split('&')[0])] + ps_score[scoreSys.index(j.split('&')[1])] + ps_score[scoreSys.index(j.split('&')[2])])\n",
    "    elif len(j.split('&')) == 4:\n",
    "      ps_score_combine[j+'_ps'] = (single_score[j.split('&')[0]]*(ps_score[scoreSys.index(j.split('&')[0])])+single_score[j.split('&')[1]]*(ps_score[scoreSys.index(j.split('&')[1])])+single_score[j.split('&')[2]]*(ps_score[scoreSys.index(j.split('&')[2])])+single_score[j.split('&')[3]]*(ps_score[scoreSys.index(j.split('&')[3])]))/(ps_score[scoreSys.index(j.split('&')[0])] + ps_score[scoreSys.index(j.split('&')[1])] + ps_score[scoreSys.index(j.split('&')[2])] + ps_score[scoreSys.index(j.split('&')[3])])\n",
    "    elif len(j.split('&')) == 5:\n",
    "      ps_score_combine[j+'_ps'] = (single_score[j.split('&')[0]]*(ps_score[scoreSys.index(j.split('&')[0])])+single_score[j.split('&')[1]]*(ps_score[scoreSys.index(j.split('&')[1])])+single_score[j.split('&')[2]]*(ps_score[scoreSys.index(j.split('&')[2])])+single_score[j.split('&')[3]]*(ps_score[scoreSys.index(j.split('&')[3])])+single_score[j.split('&')[4]]*(ps_score[scoreSys.index(j.split('&')[4])]))/(ps_score[scoreSys.index(j.split('&')[0])] + ps_score[scoreSys.index(j.split('&')[1])] + ps_score[scoreSys.index(j.split('&')[2])] + ps_score[scoreSys.index(j.split('&')[3])] + ps_score[scoreSys.index(j.split('&')[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_score_combine(models_list, avg_score_combine_seed1, ps_score_combine_seed1, ps_score[0])\n",
    "ps_score_combine(models_list, avg_score_combine_seed2, ps_score_combine_seed2, ps_score[1])\n",
    "ps_score_combine(models_list, avg_score_combine_seed3, ps_score_combine_seed3, ps_score[2])\n",
    "ps_score_combine(models_list, avg_score_combine_seed4, ps_score_combine_seed4, ps_score[3])\n",
    "ps_score_combine(models_list, avg_score_combine_seed5, ps_score_combine_seed5, ps_score[4])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform weighted rank combination by performance strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_rank_combine_seed1 = pd.DataFrame()\n",
    "ps_rank_combine_seed2 = pd.DataFrame()\n",
    "ps_rank_combine_seed3 = pd.DataFrame()\n",
    "ps_rank_combine_seed4 = pd.DataFrame()\n",
    "ps_rank_combine_seed5 = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ps_rank_combine(models_list, single_rank, ps_rank_combine, ps_score):\n",
    "  for j in models_list[len(scoreSys):]:\n",
    "    if len(j.split('&')) == 2:\n",
    "      ps_rank_combine[j+'_ps_r'] = (single_rank[j.split('&')[0]]*(1 / ps_score[scoreSys.index(j.split('&')[0])])+single_rank[j.split('&')[1]]*(1 / ps_score[scoreSys.index(j.split('&')[1])]))/(1 / ps_score[scoreSys.index(j.split('&')[0])] + 1 / ps_score[scoreSys.index(j.split('&')[1])])\n",
    "    elif len(j.split('&')) == 3:\n",
    "      ps_rank_combine[j+'_ps_r'] = (single_rank[j.split('&')[0]]*(1 / ps_score[scoreSys.index(j.split('&')[0])])+single_rank[j.split('&')[1]]*(1 / ps_score[scoreSys.index(j.split('&')[1])])+single_rank[j.split('&')[2]]*(1 / ps_score[scoreSys.index(j.split('&')[2])]))/(1 / ps_score[scoreSys.index(j.split('&')[0])] + 1 / ps_score[scoreSys.index(j.split('&')[1])] + 1 / ps_score[scoreSys.index(j.split('&')[2])])\n",
    "    elif len(j.split('&')) == 4:\n",
    "      ps_rank_combine[j+'_ps_r'] = (single_rank[j.split('&')[0]]*(1 / ps_score[scoreSys.index(j.split('&')[0])])+single_rank[j.split('&')[1]]*(1 / ps_score[scoreSys.index(j.split('&')[1])])+single_rank[j.split('&')[2]]*(1 / ps_score[scoreSys.index(j.split('&')[2])])+single_rank[j.split('&')[3]]*(1 / ps_score[scoreSys.index(j.split('&')[3])]))/(1 / ps_score[scoreSys.index(j.split('&')[0])] + 1 / ps_score[scoreSys.index(j.split('&')[1])] + 1 / ps_score[scoreSys.index(j.split('&')[2])] + 1 / ps_score[scoreSys.index(j.split('&')[3])])\n",
    "    elif len(j.split('&')) == 5:\n",
    "      ps_rank_combine[j+'_ps_r'] = (single_rank[j.split('&')[0]]*(1 / ps_score[scoreSys.index(j.split('&')[0])])+single_rank[j.split('&')[1]]*(1 / ps_score[scoreSys.index(j.split('&')[1])])+single_rank[j.split('&')[2]]*(1 / ps_score[scoreSys.index(j.split('&')[2])])+single_rank[j.split('&')[3]]*(1 / ps_score[scoreSys.index(j.split('&')[3])])+single_rank[j.split('&')[4]]*(1 / ps_score[scoreSys.index(j.split('&')[4])]))/(1 / ps_score[scoreSys.index(j.split('&')[0])] + 1 / ps_score[scoreSys.index(j.split('&')[1])] + 1 / ps_score[scoreSys.index(j.split('&')[2])] + 1 / ps_score[scoreSys.index(j.split('&')[3])] + 1 / ps_score[scoreSys.index(j.split('&')[4])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_rank_combine(models_list, avg_rank_combine_seed1, ps_rank_combine_seed1, ps_score[0])\n",
    "ps_rank_combine(models_list, avg_rank_combine_seed2, ps_rank_combine_seed2, ps_score[1])\n",
    "ps_rank_combine(models_list, avg_rank_combine_seed3, ps_rank_combine_seed3, ps_score[2])\n",
    "ps_rank_combine(models_list, avg_rank_combine_seed4, ps_rank_combine_seed4, ps_score[3])\n",
    "ps_rank_combine(models_list, avg_rank_combine_seed5, ps_rank_combine_seed5, ps_score[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rank_combine_seed1.rename(columns={'xgb': 'xgb_r', 'rf': 'rf_r', 'svm': 'svm_r', 'adb': 'adb_r', 'cnn': 'cnn_r'}, inplace=True)\n",
    "avg_rank_combine_seed2.rename(columns={'xgb': 'xgb_r', 'rf': 'rf_r', 'svm': 'svm_r', 'adb': 'adb_r', 'cnn': 'cnn_r'}, inplace=True)\n",
    "avg_rank_combine_seed3.rename(columns={'xgb': 'xgb_r', 'rf': 'rf_r', 'svm': 'svm_r', 'adb': 'adb_r', 'cnn': 'cnn_r'}, inplace=True)\n",
    "avg_rank_combine_seed4.rename(columns={'xgb': 'xgb_r', 'rf': 'rf_r', 'svm': 'svm_r', 'adb': 'adb_r', 'cnn': 'cnn_r'}, inplace=True)\n",
    "avg_rank_combine_seed5.rename(columns={'xgb': 'xgb_r', 'rf': 'rf_r', 'svm': 'svm_r', 'adb': 'adb_r', 'cnn': 'cnn_r'}, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate AUPRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_combine_list = np.hstack((np.array(avg_score_combine_seed1.columns), np.array(ds_score_combine_seed1.columns), np.array(ps_score_combine_seed1.columns)))\n",
    "AUPRC = pd.DataFrame(index = score_combine_list)\n",
    "for i in range(1, 6):\n",
    "  auprc_avg, auprc_ds, auprc_ps = [], [], []\n",
    "  for col in globals()['avg_score_combine_seed%s' %i].columns:\n",
    "    auprc_score = get_auprc(np.array(globals()['avg_score_combine_seed%s' %i][col]), y_test)\n",
    "    auprc_avg.append(auprc_score)\n",
    "  for col in globals()['ds_score_combine_seed%s' %i].columns:\n",
    "    auprc_score = get_auprc(np.array(globals()['ds_score_combine_seed%s' %i][col]), y_test)\n",
    "    auprc_ds.append(auprc_score)\n",
    "  for col in globals()['ps_score_combine_seed%s' %i].columns:\n",
    "    auprc_score = get_auprc(np.array(globals()['ps_score_combine_seed%s' %i][col]), y_test)\n",
    "    auprc_ps.append(auprc_score)\n",
    "  AUPRC['seed'+str(i)] = np.hstack((auprc_avg, auprc_ds, auprc_ps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUPRC['avg_AUPRC'] = AUPRC.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUPRC.sort_values(by='avg_AUPRC', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
